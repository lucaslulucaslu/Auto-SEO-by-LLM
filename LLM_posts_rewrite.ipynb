{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664b7590-78d8-40b8-b916-8bd7f9bbaf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from typing import TypedDict\n",
    "\n",
    "import IPython\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "import tiktoken\n",
    "\n",
    "gpt_model_name=\"gpt-4o\"\n",
    "\n",
    "llm = ChatOpenAI(model=gpt_model_name, timeout=120, temperature=0)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"auto-post-update\"\n",
    "wp_url = \"https://www.forwardpathway.com/wp-json/wp/v2\"\n",
    "wp_post_url = wp_url + \"/posts\"\n",
    "wp_media_url = wp_url + \"/media\"\n",
    "wp_tag_url = wp_url + \"/tags\"\n",
    "\n",
    "user_id = os.environ[\"wordpress_username\"]\n",
    "# user app password can be created in the user/edit user/application password\n",
    "user_app_password = os.environ[\"wordpress_pass\"]\n",
    "\n",
    "credentials = user_id + \":\" + user_app_password\n",
    "token = base64.b64encode(credentials.encode())\n",
    "header = {\"Authorization\": \"Basic \" + token.decode(\"utf-8\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d99f484-f030-48f9-ba64-24bceddc8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_list():\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    query = \"\"\"SELECT t1.cname as keyword,concat(\"https://www.forwardpathway.com/\",t1.postid) as url,t2.term_id as tag_id, t3.rank,t3.year FROM fp_ranking.`colleges` t1\n",
    "LEFT JOIN fp_forwardpathway.`wp_mmcp_terms` t2 ON t1.cname=REPLACE(t2.name,\"相关新闻\",\"\") AND t2.name LIKE \"%相关新闻\"\n",
    "LEFT JOIN fp_ranking.us_rankings t3 ON t3.postid=t1.postid AND t3.year=(select ranking FROM fp_IPEDS.latest_information) AND t3.type=1\"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    keywords_array = []\n",
    "    for row in rows:\n",
    "        keywords_array = keywords_array + [row]\n",
    "\n",
    "    query = \"\"\"SELECT keyword, url FROM fp_chatGPT.keywords\"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        keywords_array = keywords_array + [row]\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    keywords = pd.DataFrame(keywords_array, columns=[\"keyword\", \"url\",\"tag_id\",\"rank\",\"year\"])\n",
    "    keywords = keywords.reset_index(drop=True)\n",
    "\n",
    "    keywords = keywords.reindex(\n",
    "        keywords[\"keyword\"].str.len().sort_values(ascending=False).index\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return keywords\n",
    "\n",
    "\n",
    "keywords = get_keywords_list()\n",
    "\n",
    "\n",
    "def get_update_post_ID():\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    query = \"\"\"SELECT t3.ID FROM (SELECT t2.ID,t2.post_modified FROM fp_forwardpathway.`wp_mmcp_term_relationships` t1\n",
    "JOIN fp_forwardpathway.wp_mmcp_posts t2 ON t2.ID=t1.object_id AND t2.post_status=\"publish\"\n",
    "WHERE t1.`term_taxonomy_id` IN (3,2294,2295,2293,2180,1,1758,35,2350,2351,36,6)\n",
    "GROUP BY t2.ID ORDER BY t2.post_modified ASC LIMIT 10) t3\n",
    "ORDER BY RAND() LIMIT 1\"\"\"\n",
    "    cursor.execute(query)\n",
    "    row = cursor.fetchone()\n",
    "    post_ID = int(row[\"ID\"])\n",
    "\n",
    "    return post_ID\n",
    "\n",
    "\n",
    "def insert_keyword_url(content):\n",
    "    soup = BeautifulSoup(content,\"html.parser\")\n",
    "    for key, row in keywords.iterrows():\n",
    "        keyword = row[\"keyword\"]\n",
    "        url = row[\"url\"]\n",
    "        new_tag = soup.new_tag(\"a\", href=url)\n",
    "        new_tag.string = keyword\n",
    "        void_tags = [\"a\", \"h1\", \"h2\", \"h3\", \"h4\"]\n",
    "        pattern = re.compile(keyword)\n",
    "        results = soup.find_all(string=pattern)\n",
    "        for string_element in results:\n",
    "            parents_set = set([x.name for x in string_element.parents])\n",
    "            if any([x in parents_set for x in void_tags]):\n",
    "                continue\n",
    "            new_element = BeautifulSoup(\n",
    "                string_element.replace(keyword, str(new_tag), 1), \"html.parser\"\n",
    "            )\n",
    "            string_element = string_element.replace_with(new_element)\n",
    "            break\n",
    "    return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551c6fd1-9f0d-4012-b28f-401a97beb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    post_ID: int\n",
    "    URL: str\n",
    "    raw_html: str\n",
    "    original_content: str\n",
    "    text_content: str\n",
    "    revised_content: str\n",
    "    revises: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d081567-991b-44b2-8e03-3c6c40c5f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_content(state):\n",
    "    post_ID = state[\"post_ID\"]\n",
    "    URL = \"https://www.forwardpathway.com/\" + str(post_ID)\n",
    "    response = retrieve_post(post_ID)\n",
    "    raw_html = response.json()[\"content\"][\"rendered\"]\n",
    "    soup_content = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    # soup.html.unwrap()\n",
    "    # soup.body.unwrap()\n",
    "    imgs = soup_content.find_all(\"img\")\n",
    "    remove_attrs = set([\"srcset\", \"class\", \"decoding\", \"height\", \"sizes\", \"width\"])\n",
    "    for img in imgs:\n",
    "        img_attrs = dict(img.attrs)\n",
    "        for img_attr in img_attrs:\n",
    "            if img_attr in remove_attrs:\n",
    "                del img.attrs[img_attr]\n",
    "    if soup_content is not None:\n",
    "        elements = soup_content.find_all(\n",
    "            True,\n",
    "            class_=[\n",
    "                \"crp_related\",\n",
    "                \"topBanner\",\n",
    "                \"bottomBanner\",\n",
    "                \"wp-block-advgb-summary\",\n",
    "                \"yoast-table-of-contents\",\n",
    "                \"exclusiveStatement\",\n",
    "                \"companyLocation\",\n",
    "                \"CommentsAndShare\",\n",
    "                \"AI_Summary\",\n",
    "                \"AI_QA\",\n",
    "                \"btn-group\",\n",
    "            ],\n",
    "        )\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "        elements = soup_content.find_all(\n",
    "            True,\n",
    "            id=[\n",
    "                \"crp_related\",\n",
    "            ],\n",
    "        )\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "        elements = soup_content.findAll([\"svg\", \"style\", \"script\", \"noscript\"])\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "    original_content = str(soup_content.find_all(True))\n",
    "    return {\n",
    "        \"raw_html\": raw_html,\n",
    "        \"original_content\": original_content,\n",
    "        \"URL\": URL,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41845129-0051-497b-9e91-c7868a0eed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class revise_single(BaseModel):\n",
    "    comment: str = Field(description=\"文章具体修改意见\")\n",
    "    search_query: str = Field(\n",
    "        description=\"文章修改所需资料的具体搜索词条，可以用该词条在Google上搜索所需的资料来修改文章\"\n",
    "    )\n",
    "\n",
    "\n",
    "class revise_output(BaseModel):\n",
    "    revises: list[revise_single] = Field(\n",
    "        description=\"包含文章修改意见和具体搜索词条的数组\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_revise_comments(state):\n",
    "    post_content = state[\"original_content\"]\n",
    "    revise_comment_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"今天的日期是{today}，下面将给出一篇网站文章，请对该文章的内容提出具体的修改意见，比如使用数据过时、前后逻辑不清晰或者用词不当等你觉得不好的地方。\\\n",
    "                如果文章太短，比如说文章长度少于2000个中文字，请给出增加文章长度的建议，建议增加的内容也请详细给出。\\\n",
    "                    如果遇到某一个表格太长，比如超过五十行数据的请给出精简表格到五十行并引用出处的修改意见，但不多于二十行数据的不要修改，这条修改意见应优先处理放在第一条意见上。修改意见需要与具体的文章内容一一对应具体给出。\\\n",
    "                    同时对应每一条修改意见请给出具体的搜索词条，用该词条可以在Google上搜索相应的资料，搜索词条与修改意见必须一一对应。\\\n",
    "                    请给出3条修改意见，并将每一条修改意见与搜索词条放入对应的输出数组当中\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"文章内容: {content}\"),\n",
    "        ]\n",
    "    )\n",
    "    today = datetime.datetime.now().strftime(\"%Y年%m月%d日\")\n",
    "    revise_comment_llm = llm.with_structured_output(revise_output)\n",
    "    revise_comment_chain = revise_comment_prompt | revise_comment_llm\n",
    "    response = revise_comment_chain.invoke({\"today\": today, \"content\": post_content})\n",
    "    return {\"revises\": response.revises}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ce55c-6b86-41b4-9a7a-8788b48f91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_post(state):\n",
    "    revises = state[\"revises\"]\n",
    "    revise_content = state[\"original_content\"]\n",
    "    revise_n = 0\n",
    "    system_common=\"\"\"你是一名专业的网站内容编辑，下面将给出一篇网站文章，并给你一条修改意见以及与该修改意见相关的一些参考资料，请参考修改意见与参考资料对原文章进行修改，尽量保持原文章的长度不减少。\\\n",
    "                        如果更新内容为一张表格中的数据，请对全表格进行更新，且更新内容必须为参考资料中的内容，如果参考资料中不包含关键信息的，请删除原表格中的内容。\\\n",
    "                        修改后的输出结果请输出修改后全文，需要原文的全文修改版。遇到表格要进行表格排版；各级标题也要全文统一格式排版。\\\n",
    "                        尽量保留原文章中的图片。如果原文章中遇到美国大学只有英文名没有中文名的，请添加中文名翻译。\\\n",
    "                        如果修改是参考了搜索资料，请在文章内容中添加参考标记与编号，并在文章末尾添加参考过的资料与编号，只添加参考过的资料，参考资料部分要统一排版并编号，编号采用\"1.\"、\"2.\"、\"3.\"格式。\\\n",
    "                        \"\"\"\n",
    "                        \n",
    "    for revise in revises:\n",
    "        if revise_n == 0:\n",
    "            revise_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        system_common+\"\"\"文章原文如果有参考资料部分的，请用新的参考资料覆盖所有的旧参考资料。最终输出结果必须是markdown格式输出，但是不要在文章最前端添加markdown标志。\"\"\",\n",
    "                    ),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        \"\\n\\n修改意见:{comment}\\n\\n参考资料:{docs}\\n\\n原文章内容: {content}\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            revise_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        system_common+\"\"\"参考资料部分要与原有的参考资料部分统一排版并编号，合并类似的参考资料。\\\n",
    "                        如果资料做了更新，对应的参考资料也进行更新。最终输出结果必须是markdown格式输出，但是不要在文章最前端添加markdown标志。\"\"\",\n",
    "                    ),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        \"\\n\\n修改意见:{comment}\\n\\n参考资料:{docs}\\n\\n原文章内容: {content}\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        revise_chain = revise_prompt | llm | StrOutputParser()\n",
    "        comment = revise.comment\n",
    "        search_query = revise.search_query\n",
    "        search = GoogleSerperAPIWrapper()\n",
    "        results = search.results(search_query + \" -filetype:pdf -site:forwardpathway.com\")\n",
    "        links = []\n",
    "        docs = []\n",
    "        print(\"--------get search results done!---------------\")\n",
    "        search_result_count = 0\n",
    "        for x in results[\"organic\"]:\n",
    "            if search_result_count >= 2:\n",
    "                break\n",
    "            try:\n",
    "                loader = WebBaseLoader(\n",
    "                    x[\"link\"], requests_kwargs={\"timeout\": 15}, continue_on_failure=True\n",
    "                )\n",
    "                new_doc=loader.load()\n",
    "            except:\n",
    "                continue\n",
    "            encoding = tiktoken.encoding_for_model(gpt_model_name)\n",
    "            token_length = len(encoding.encode(str(new_doc[0])))\n",
    "            if token_length <=100000:\n",
    "                docs = docs + loader.load()\n",
    "                search_result_count += 1\n",
    "\n",
    "        print(\"--------load docs done!---------------\")\n",
    "        revise_content = revise_chain.invoke(\n",
    "            {\"content\": revise_content, \"comment\": comment, \"docs\": docs}\n",
    "        )\n",
    "        revise_n += 1\n",
    "        print(\"-----------{}x revise done!---------------\".format(revise_n))\n",
    "    return {\"revised_content\": revise_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406daaab-5461-4a55-a29f-3a7070a7e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_file(file_path):\n",
    "    media = {\n",
    "        \"file\": open(file_path, \"rb\"),\n",
    "        \"caption\": \"LLM_auto_post_test_file_\" + file_path,\n",
    "    }\n",
    "    response = requests.post(wp_media_url, headers=header, files=media)\n",
    "    return response\n",
    "\n",
    "\n",
    "def post_post(post_ID, article_body, featured_media_id=0):\n",
    "    post_data = {\n",
    "        \"content\": article_body,\n",
    "        \"featured_media\": featured_media_id,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        wp_post_url + \"/\" + str(post_ID), headers=header, json=post_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def retrieve_post(post_ID):\n",
    "    response = requests.get(wp_post_url + \"/\" + str(post_ID), headers=header)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1a762d-e07e-47f3-b5bb-f5af9877136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_post(state):\n",
    "    post_ID = state[\"post_ID\"]\n",
    "    content = state[\"revised_content\"]\n",
    "    content = markdown.markdown(content, extensions=[\"tables\",'footnotes'])\n",
    "    content = insert_keyword_url(content)\n",
    "    # IPython.display.HTML(content)\n",
    "    post_post(post_ID, content)\n",
    "    folder = get_local_folder()\n",
    "    filepath = os.path.join(folder, \"post_rewrite.csv\")\n",
    "    df = pd.DataFrame(\n",
    "        [[post_ID, state[\"raw_html\"], content]],\n",
    "        columns=[\"post_ID\", \"raw_html\", \"revised\"],\n",
    "    )\n",
    "    df.to_csv(filepath, mode=\"a\", index=False,header=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d2e828-0aeb-4db8-8458-8528e44c470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"get_post_content\", get_post_content)\n",
    "workflow.add_node(\"get_revise_comments\", get_revise_comments)\n",
    "workflow.add_node(\"revise_post\", revise_post)\n",
    "workflow.add_node(\"update_post\", update_post)\n",
    "\n",
    "workflow.set_entry_point(\"get_post_content\")\n",
    "workflow.add_edge(\"get_post_content\", \"get_revise_comments\")\n",
    "workflow.add_edge(\"get_revise_comments\", \"revise_post\")\n",
    "workflow.add_edge(\"revise_post\", \"update_post\")\n",
    "workflow.add_edge(\"update_post\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051f98d-0294-462b-9526-a6f3066992cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------get search results done!---------------\n",
      "--------load docs done!---------------\n",
      "-----------1x revise done!---------------\n",
      "--------get search results done!---------------\n",
      "--------load docs done!---------------\n",
      "-----------2x revise done!---------------\n",
      "--------get search results done!---------------\n"
     ]
    }
   ],
   "source": [
    "#app.invoke({\"post_ID\": get_update_post_ID()})\n",
    "app.invoke({\"post_ID\": 16673})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66340eb-5037-4ac9-b4e7-aac89d21a3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2254c6a-db53-4a40-a712-b318fb219582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
