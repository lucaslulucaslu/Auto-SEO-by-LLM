{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664b7590-78d8-40b8-b916-8bd7f9bbaf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from typing import TypedDict\n",
    "\n",
    "import IPython\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import requests\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "\n",
    "gpt_model_name = \"gpt-4o\"\n",
    "\n",
    "llm = ChatOpenAI(model=gpt_model_name, timeout=120, temperature=0)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"auto-post-update\"\n",
    "wp_url = \"https://www.forwardpathway.com/wp-json/wp/v2\"\n",
    "wp_post_url = wp_url + \"/posts\"\n",
    "wp_media_url = wp_url + \"/media\"\n",
    "wp_tag_url = wp_url + \"/tags\"\n",
    "\n",
    "user_id = os.environ[\"wordpress_username\"]\n",
    "# user app password can be created in the user/edit user/application password\n",
    "user_app_password = os.environ[\"wordpress_pass\"]\n",
    "\n",
    "credentials = user_id + \":\" + user_app_password\n",
    "token = base64.b64encode(credentials.encode())\n",
    "header = {\"Authorization\": \"Basic \" + token.decode(\"utf-8\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d99f484-f030-48f9-ba64-24bceddc8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_list():\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    query = \"\"\"SELECT t1.cname as keyword,concat(\"https://www.forwardpathway.com/\",t1.postid) as url,t2.term_id as tag_id, t3.rank,t3.year FROM fp_ranking.`colleges` t1\n",
    "LEFT JOIN fp_forwardpathway.`wp_mmcp_terms` t2 ON t1.cname=REPLACE(t2.name,\"相关新闻\",\"\") AND t2.name LIKE \"%相关新闻\"\n",
    "LEFT JOIN fp_ranking.us_rankings t3 ON t3.postid=t1.postid AND t3.year=(select ranking FROM fp_IPEDS.latest_information) AND t3.type=1\"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    keywords_array = []\n",
    "    for row in rows:\n",
    "        keywords_array = keywords_array + [row]\n",
    "\n",
    "    query = \"\"\"SELECT keyword, url FROM fp_chatGPT.keywords\"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        keywords_array = keywords_array + [row]\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    keywords = pd.DataFrame(\n",
    "        keywords_array, columns=[\"keyword\", \"url\", \"tag_id\", \"rank\", \"year\"]\n",
    "    )\n",
    "    keywords = keywords.reset_index(drop=True)\n",
    "\n",
    "    keywords = keywords.reindex(\n",
    "        keywords[\"keyword\"].str.len().sort_values(ascending=False).index\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return keywords\n",
    "\n",
    "\n",
    "keywords = get_keywords_list()\n",
    "\n",
    "\n",
    "def get_update_post_ID():\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    query = \"\"\"SELECT t3.ID FROM (SELECT t2.ID,t2.post_modified FROM fp_forwardpathway.`wp_mmcp_term_relationships` t1\n",
    "JOIN fp_forwardpathway.wp_mmcp_posts t2 ON t2.ID=t1.object_id AND t2.post_status=\"publish\"\n",
    "WHERE t1.`term_taxonomy_id` IN (3,2294,2295,2293,2180,1,1758,35,2350,2351,36,6)\n",
    "GROUP BY t2.ID ORDER BY t2.post_modified ASC LIMIT 10) t3\n",
    "ORDER BY RAND() LIMIT 1\"\"\"\n",
    "    cursor.execute(query)\n",
    "    row = cursor.fetchone()\n",
    "    post_ID = int(row[\"ID\"])\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return post_ID\n",
    "\n",
    "\n",
    "def update_long_post(post_ID):\n",
    "    connection = pymysql.connect(\n",
    "        db=os.environ[\"db_name\"],\n",
    "        user=os.environ[\"db_user\"],\n",
    "        passwd=os.environ[\"db_pass\"],\n",
    "        host=os.environ[\"db_host\"],\n",
    "        port=3306,\n",
    "        cursorclass=pymysql.cursors.DictCursor,\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    query = (\n",
    "        \"\"\"INSERT IGNORE INTO fp_chatGPT.long_posts (`postid`) VALUES ({})\"\"\".format(\n",
    "            post_ID\n",
    "        )\n",
    "    )\n",
    "    cursor.execute(query)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return post_ID\n",
    "\n",
    "\n",
    "def insert_keyword_url(content):\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    for key, row in keywords.iterrows():\n",
    "        keyword = row[\"keyword\"]\n",
    "        url = row[\"url\"]\n",
    "        new_tag = soup.new_tag(\"a\", href=url)\n",
    "        new_tag.string = keyword\n",
    "        void_tags = [\"a\", \"h1\", \"h2\", \"h3\", \"h4\"]\n",
    "        pattern = re.compile(keyword)\n",
    "        results = soup.find_all(string=pattern)\n",
    "        for string_element in results:\n",
    "            parents_set = set([x.name for x in string_element.parents])\n",
    "            if any([x in parents_set for x in void_tags]):\n",
    "                continue\n",
    "            new_element = BeautifulSoup(\n",
    "                string_element.replace(keyword, str(new_tag), 1), \"html.parser\"\n",
    "            )\n",
    "            string_element = string_element.replace_with(new_element)\n",
    "            break\n",
    "    return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551c6fd1-9f0d-4012-b28f-401a97beb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    post_ID: int\n",
    "    URL: str\n",
    "    raw_html: str\n",
    "    original_content: str\n",
    "    text_content: str\n",
    "    revised_content: str\n",
    "    revises: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d081567-991b-44b2-8e03-3c6c40c5f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_content(state):\n",
    "    post_ID = state[\"post_ID\"]\n",
    "    URL = \"https://www.forwardpathway.com/\" + str(post_ID)\n",
    "    response = retrieve_post(post_ID)\n",
    "    raw_html = response.json()[\"content\"][\"rendered\"]\n",
    "    soup_content = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    # soup.html.unwrap()\n",
    "    # soup.body.unwrap()\n",
    "    imgs = soup_content.find_all(\"img\")\n",
    "    remove_attrs = set([\"srcset\", \"class\", \"decoding\", \"height\", \"sizes\", \"width\"])\n",
    "    for img in imgs:\n",
    "        img_attrs = dict(img.attrs)\n",
    "        for img_attr in img_attrs:\n",
    "            if img_attr in remove_attrs:\n",
    "                del img.attrs[img_attr]\n",
    "    if soup_content is not None:\n",
    "        elements = soup_content.find_all(\n",
    "            True,\n",
    "            class_=[\n",
    "                \"crp_related\",\n",
    "                \"topBanner\",\n",
    "                \"bottomBanner\",\n",
    "                \"wp-block-advgb-summary\",\n",
    "                \"yoast-table-of-contents\",\n",
    "                \"exclusiveStatement\",\n",
    "                \"companyLocation\",\n",
    "                \"CommentsAndShare\",\n",
    "                \"AI_Summary\",\n",
    "                \"AI_QA\",\n",
    "                \"btn-group\",\n",
    "            ],\n",
    "        )\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "        elements = soup_content.find_all(\n",
    "            True,\n",
    "            id=[\n",
    "                \"crp_related\",\n",
    "            ],\n",
    "        )\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "        elements = soup_content.findAll([\"svg\", \"style\", \"script\", \"noscript\"])\n",
    "        for element in elements:\n",
    "            element.decompose()\n",
    "    original_content = str(soup_content.find_all(True))\n",
    "\n",
    "    return {\n",
    "        \"raw_html\": raw_html,\n",
    "        \"original_content\": original_content,\n",
    "        \"URL\": URL,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41845129-0051-497b-9e91-c7868a0eed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class revise_single(BaseModel):\n",
    "    comment: str = Field(description=\"文章具体修改意见\")\n",
    "    search_query: str = Field(\n",
    "        description=\"文章修改所需资料的具体英文搜索词条，可以用该词条在Google上搜索所需的资料来修改文章\"\n",
    "    )\n",
    "\n",
    "\n",
    "class revise_output(BaseModel):\n",
    "    revises: list[revise_single] = Field(\n",
    "        description=\"包含文章修改意见和具体搜索词条的数组\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_revise_comments(state):\n",
    "    post_content = state[\"original_content\"]\n",
    "    revise_comment_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"今天的日期是{today}，下面将给出一篇网站文章，请对该文章的内容提出具体的修改意见和搜索词条。修改意见可以包含但不限于以下几个方面：\\\n",
    "                使用数据过时、前后逻辑不清晰、用词是否恰当、前后文是否对应。\n",
    "                修改意见要求：\n",
    "                1. 内容扩展建议：如果文章长度少于2000个中文字，请提供增加文章长度的建议，并详细描述应增加的内容。\n",
    "                2. 数据和信息的准确性：检查文章中的数据和信息是否准确和最新。如果发现数据过时，请提出具体的修改建议。\n",
    "                3. 逻辑和结构：评估文章的逻辑和结构，确保前后文连贯。如果发现逻辑不清晰或结构混乱的地方，请指出并给出修改建议。\n",
    "                4. 用词和语言：检查文章的用词是否恰当，语言是否流畅。如果发现用词不当或语言不流畅的地方，请提出修改建议。\n",
    "                5. 引用和出处：检查文章中的引用和出处是否清晰明确。如果发现引用不清楚或缺乏出处的地方，请提出修改建议。\n",
    "                6. 修改意见要具体：请具体指出文章中哪些部分需要修改，详细描述不好的地方，如数据过时、前后逻辑不清晰、用词不当等。\n",
    "                搜索词条要求：修改意见与搜索词条需一一对应。每一条修改意见应对应一个具体的搜索词条。搜索词条必须是英文，且应能在Google上搜索到相应的资料。\n",
    "                输出格式：请给出3条修改意见，并将每一条修改意见与搜索词条放入对应的输出数组中。确保每条修改意见具体明确，并对应相关的搜索词条。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"文章内容: {content}\"),\n",
    "        ]\n",
    "    )\n",
    "    today = datetime.datetime.now().strftime(\"%Y年%m月%d日\")\n",
    "    revise_comment_llm = llm.with_structured_output(revise_output)\n",
    "    revise_comment_chain = revise_comment_prompt | revise_comment_llm\n",
    "    response = revise_comment_chain.invoke({\"today\": today, \"content\": post_content})\n",
    "    return {\"revises\": response.revises}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ce55c-6b86-41b4-9a7a-8788b48f91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_post(state):\n",
    "    concat_max = 3\n",
    "    revises = state[\"revises\"]\n",
    "    revise_content = state[\"original_content\"]\n",
    "    revise_n = 0\n",
    "    system_common = \"\"\"任务说明：你是一名专业的网站内容编辑。下面将给出一篇网站文章，并提供一条修改意见以及与该修改意见相关的一些参考资料。请根据修改意见和参考资料对原文章进行修改，尽量保持文章长度不减少。\n",
    "    修改要求：\n",
    "    1. 内容更新：请参考修改意见和相关资料对原文进行修改。如果更新内容涉及表格数据，请对整个表格进行更新，且更新内容必须来自参考资料。如果参考资料中不包含关键信息，请删除原表格中的相关内容。\n",
    "    2. 排版要求：修改后的文章需输出全文，包括修改后的内容。对遇到的表格进行表格排版，各级标题统一格式排版。尽量保留原文章中的图片。\n",
    "    3. 中文名翻译：如果原文中提到的美国大学只有英文名，请添加中文名翻译。\n",
    "    4. 参考标记和编号：如果修改是参考了搜索资料，请在文章内容中添加参考标记与编号，并在文章末尾添加参考过的资料与编号。参考资料部分需统一排版并编号。\"\"\"\n",
    "    system_diff = [\n",
    "        \"\"\"\\n\\n文章原文如果有参考资料部分的，请用新的参考资料覆盖所有的旧参考资料。最终输出结果必须是markdown格式输出，但是不要在文章最前端添加markdown标志。\"\"\",\n",
    "        \"\"\"\\n\\n参考资料部分要与原有的参考资料部分统一排版并编号，合并类似的参考资料.如果资料做了更新，对应的参考资料也进行更新。最终输出结果必须是markdown格式输出，但是不要在文章最前端添加markdown标志。\"\"\",\n",
    "    ]\n",
    "    for revise in revises:\n",
    "        original_content = revise_content\n",
    "        revise_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_common + system_diff[revise_n >= 1]),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"\\n\\n修改意见:{comment}\\n\\n参考资料:{docs}\\n\\n原文章内容: {content}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        revise_chain = revise_prompt | llm\n",
    "        comment = revise.comment\n",
    "        search_query = revise.search_query\n",
    "        search = GoogleSerperAPIWrapper()\n",
    "        results = search.results(\n",
    "            search_query + \" -filetype:pdf -site:forwardpathway.com\"\n",
    "        )\n",
    "        links = []\n",
    "        docs = []\n",
    "        print(\"--------get search results done!---------------\")\n",
    "        search_result_count = 0\n",
    "        for x in results[\"organic\"]:\n",
    "            if search_result_count >= 2:\n",
    "                break\n",
    "            try:\n",
    "                loader = WebBaseLoader(\n",
    "                    x[\"link\"], requests_kwargs={\"timeout\": 15}, continue_on_failure=True\n",
    "                )\n",
    "                new_doc = loader.load()\n",
    "            except:\n",
    "                continue\n",
    "            encoding = tiktoken.encoding_for_model(gpt_model_name)\n",
    "            token_length = len(encoding.encode(str(new_doc[0])))\n",
    "            if token_length <= 50000:\n",
    "                docs = docs + loader.load()\n",
    "                search_result_count += 1\n",
    "\n",
    "        print(\"--------load docs done!---------------\")\n",
    "        response = revise_chain.invoke(\n",
    "            {\"content\": revise_content, \"comment\": comment, \"docs\": docs}\n",
    "        )\n",
    "        revise_content = response.content\n",
    "        stop_reason = response.response_metadata[\"finish_reason\"]\n",
    "        concat_count = 0\n",
    "        while stop_reason == \"length\":\n",
    "            if concat_count >= concat_max:\n",
    "                raise Exception(\"max count reached\")\n",
    "            revise_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        \"你已经生成了第一部分输出内容，请根据下面相同的任务需求及第一部分输出内容继续生成剩余的内容。\\n\\n\"\n",
    "                        + system_common\n",
    "                        + system_diff[revise_n >= 1],\n",
    "                    ),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        \"\\n\\n修改意见:{comment}\\n\\n参考资料:{docs}\\n\\n原文章内容: {content}\\n\\n第一部分输出内容：{first_part_content}\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            revise_chain = revise_prompt | llm\n",
    "            response = revise_chain.invoke(\n",
    "                {\n",
    "                    \"content\": original_content,\n",
    "                    \"comment\": comment,\n",
    "                    \"docs\": docs,\n",
    "                    \"first_part_content\": revise_content,\n",
    "                }\n",
    "            )\n",
    "            revise_content = revise_content + response.content\n",
    "            stop_reason = response.response_metadata[\"finish_reason\"]\n",
    "            concat_count += 1\n",
    "        revise_n += 1\n",
    "        print(\"-----------{}x revise done!---------------\".format(revise_n))\n",
    "    return {\"revised_content\": revise_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406daaab-5461-4a55-a29f-3a7070a7e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_file(file_path):\n",
    "    media = {\n",
    "        \"file\": open(file_path, \"rb\"),\n",
    "        \"caption\": \"LLM_auto_post_test_file_\" + file_path,\n",
    "    }\n",
    "    response = requests.post(wp_media_url, headers=header, files=media)\n",
    "    return response\n",
    "\n",
    "\n",
    "def post_post(post_ID, article_body, featured_media_id=0):\n",
    "    post_data = {\n",
    "        \"content\": article_body,\n",
    "        \"featured_media\": featured_media_id,\n",
    "    }\n",
    "    response = requests.post(\n",
    "        wp_post_url + \"/\" + str(post_ID), headers=header, json=post_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def retrieve_post(post_ID):\n",
    "    response = requests.get(wp_post_url + \"/\" + str(post_ID), headers=header)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1a762d-e07e-47f3-b5bb-f5af9877136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_post(state):\n",
    "    post_ID = state[\"post_ID\"]\n",
    "    content = state[\"revised_content\"]\n",
    "    content = markdown.markdown(content, extensions=[\"tables\", \"footnotes\"])\n",
    "    content = insert_keyword_url(content)\n",
    "    # IPython.display.HTML(content)\n",
    "    post_post(post_ID, content)\n",
    "    folder = get_local_folder()\n",
    "    filepath = os.path.join(folder, \"post_rewrite.csv\")\n",
    "    df = pd.DataFrame(\n",
    "        [[post_ID, state[\"raw_html\"], content]],\n",
    "        columns=[\"post_ID\", \"raw_html\", \"revised\"],\n",
    "    )\n",
    "    df.to_csv(filepath, mode=\"a\", index=False, header=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d2e828-0aeb-4db8-8458-8528e44c470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"get_post_content\", get_post_content)\n",
    "workflow.add_node(\"get_revise_comments\", get_revise_comments)\n",
    "workflow.add_node(\"revise_post\", revise_post)\n",
    "workflow.add_node(\"update_post\", update_post)\n",
    "\n",
    "workflow.set_entry_point(\"get_post_content\")\n",
    "workflow.add_edge(\"get_post_content\", \"get_revise_comments\")\n",
    "workflow.add_edge(\"get_revise_comments\", \"revise_post\")\n",
    "workflow.add_edge(\"revise_post\", \"update_post\")\n",
    "workflow.add_edge(\"update_post\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051f98d-0294-462b-9526-a6f3066992cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"post_ID\": get_update_post_ID()})\n",
    "# app.invoke({\"post_ID\": 16673})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66340eb-5037-4ac9-b4e7-aac89d21a3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2254c6a-db53-4a40-a712-b318fb219582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
