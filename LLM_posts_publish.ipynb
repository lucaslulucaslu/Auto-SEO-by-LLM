{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cab3aa-d600-4e0c-8b94-5b4064d75a40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import markdown2\n",
    "import requests\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "from utilities.wordpress_tools import (\n",
    "    get_news_urls,\n",
    "    insert_keyword_url,\n",
    "    post_wordpress_file,\n",
    "    post_wordpress_post,\n",
    "    set_news_url_flag,\n",
    "    tags_to_IDs,\n",
    "    tags_to_IDs_en,\n",
    "    update_summary_qa,\n",
    "    image_insert_fuc,\n",
    ")\n",
    "from schemas.schemas_publish import (\n",
    "    OutlinesList,\n",
    "    GraphState,\n",
    "    SummaryOutput,\n",
    "    MorePoints,\n",
    "    MetaFormat,\n",
    ")\n",
    "from utilities.llm_wrapper import llm_wrapper, llm_image_wrapper\n",
    "from utilities.web_search_wrapper import web_search_wrapper\n",
    "from utilities.web_loader_wrapper import web_loader_wrapper\n",
    "from langsmith import traceable\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"college-news-auto-post\"\n",
    "\n",
    "MAX_WEB_URL = 5\n",
    "MAX_QUERY_RESULT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e0c942-2c1f-4f2c-a63b-71682195898d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@traceable\n",
    "def summary_from_url(url):\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "    loader =SeleniumURLLoader(urls=[])\n",
    "    docs=loader.load()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = web_loader_wrapper(url)\n",
    "        summary_sys_prompt = \"\"\"\n",
    "        Task Description: You are a professional news summarizer. Based on the content of the webpage provided, create a news summary of \\\n",
    "            approximately 500 English words.The summary must be written in English, ensuring comprehensive coverage of the information.\n",
    "        Specific Requirements:\n",
    "        1. News Summary: Extract the core content of the news, ensuring the information is complete and coherent. \\\n",
    "            The length should be around 500 English words.\n",
    "        2. Title Extraction: If the webpage already contains a title, extract it. If there is no title, summarize an appropriate title based on the content. \\\n",
    "            The title must be in English.\n",
    "        3. Date Information: If the webpage includes a publication date, make sure to include this date in the news summary, \\\n",
    "            using a format that includes the year.\n",
    "        4. Content Related to U.S. Universities: If the webpage mentions U.S. universities (such as Harvard University, Yale University, etc.), \\\n",
    "        ensure that any related information (e.g., connection to the event or the author) is included in the summary.\n",
    "        \"\"\"\n",
    "        summary_user_prompt = f\"\"\"content: {content}\"\"\"\n",
    "        response = llm_wrapper(summary_sys_prompt, summary_user_prompt, SummaryOutput)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404 or e.response.status_code == 403:\n",
    "            response = \"404\"\n",
    "        else:\n",
    "            response = None\n",
    "    except:\n",
    "        response = None\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c397edf-8768-42f7-a657-f94834ad31eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    url = state[\"url\"]\n",
    "    response = summary_from_url(url)\n",
    "    if response is None:\n",
    "        set_news_url_flag(url)\n",
    "        raise Exception(\"Orginal url None error\")\n",
    "    if response == \"404\":\n",
    "        set_news_url_flag(url)\n",
    "        raise Exception(\"Orginal url 403/404 error\")\n",
    "    title = response.title\n",
    "    summary = response.summary\n",
    "    print(\"Finish Initial Summary: \", url)\n",
    "    url_base = url.split(\"?\")[0]\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"topic\": \"This is the original article summary.\",\n",
    "                \"url\": url_base,\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "            }\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5785bf-d1e7-4db8-9796-46db2331b2bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def more_topics(state):\n",
    "    summary = state[\"summary\"]\n",
    "    summary_system_prompt = \"\"\"From the original summary provided by the user, identify five topics that are \\\n",
    "        closely related to the content and can stimulate further discussion. For each topic, generate a concise \\\n",
    "            and relevant search query in English to represent the discussion point.\"\"\"\n",
    "    summary_user_prompt = f\"\"\"summary: {summary}\"\"\"\n",
    "    response = llm_wrapper(summary_system_prompt, summary_user_prompt, MorePoints)\n",
    "    topics = response.more\n",
    "    return {\"topics\": topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e90b592-d50e-4c7c-8566-1fda5443d277",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def topics_to_search(state):\n",
    "    return [\n",
    "        Send(\"web_search\", {\"query\": topic}) for topic in state[\"topics\"][:MAX_WEB_URL]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933f7ba9-6ccb-471d-a6e7-b986154a7ab8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    query = state[\"query\"]\n",
    "    results = web_search_wrapper(query)\n",
    "    n_results = 0\n",
    "    documents = []\n",
    "    for result in results[\"news\"]:\n",
    "        if n_results >= MAX_QUERY_RESULT:\n",
    "            break\n",
    "        url = result[\"link\"]\n",
    "        response = summary_from_url(url)\n",
    "        if response is None:\n",
    "            print(url, \" --- none response!\")\n",
    "            continue\n",
    "        elif response == \"404\":\n",
    "            print(url, \" --- 403/404 response\")\n",
    "            continue\n",
    "        else:\n",
    "            print(url, \" --- done!\")\n",
    "            summary = response.summary\n",
    "            title = response.title\n",
    "            documents = documents + [\n",
    "                {\"topic\": query, \"url\": url, \"title\": title, \"summary\": summary}\n",
    "            ]\n",
    "            n_results = n_results + 1\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15782c1a-5a92-4c8a-a048-b96e2d8b6f54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_outline_cn(state):\n",
    "    documents = state[\"documents\"]\n",
    "    outline_system_prompt = \"\"\"\n",
    "    你是一名专注于美国大学新闻的专业评论员。你将收到新闻标题、链接和新闻摘要，以及相关讨论主题和相关文章链接及其摘要。基于这些信息，\\\n",
    "        你的任务是为一篇3000字的评论文章创建详细的写作大纲。你的任务包括以下要求：\n",
    "    1. 你不需要撰写完整的评论文章，而是提供一个全面的写作规划大纲。\n",
    "    2. 将文章分为3到5个部分，每个部分应有一个明确的标题，标题放入`title`字段中。\n",
    "    3. 对于每个部分，详细描述该部分要涵盖的具体内容，讨论如何展开，以及信息应如何结构化。尽可能提供清晰且具体的指导。描述放入`description`字段中。\n",
    "    4. 根据3000字的总目标，估算每个部分的合适字数分配。字数放入`words`字段中。\n",
    "    5. 在撰写大纲时，确保你仅基于提供的信息，并据此规划文章结构。\n",
    "    6. 每个部分的顺序应与最终文章中的部分顺序一致。\n",
    "    7. 所有输出内容都应该是中文。\n",
    "    \"\"\"\n",
    "    outline_user_prompt = f\"原始新闻及相关讨论主题的材料：{documents}\"\n",
    "    response = llm_wrapper(outline_system_prompt, outline_user_prompt, OutlinesList)\n",
    "    sections = response.sections\n",
    "    return {\"sections\": sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3347ba-c75f-4beb-8616-2f18ec66ff46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_outline_en(state):\n",
    "    documents = state[\"documents\"]\n",
    "    outline_system_prompt = \"\"\"\n",
    "    You are a professional commentator specializing in news about U.S. universities. You will be provided with a headline, link, \\\n",
    "        and summary of a piece of original news, along with related discussion topics and links to relevant articles and their summaries. \\\n",
    "            Based on this information, your task is to create a detailed outline for a 3,000-word commentary article.\n",
    "    Please follow these instructions:\n",
    "    1. You do not need to write the full article; instead, provide a comprehensive outline.\n",
    "    2. Divide the article into 3 to 5 sections, each with a clear title (use the `title` field).\n",
    "    3. For each section, describe the specific content to be covered, explain how the discussion should develop, and outline the \\\n",
    "        structure of the information (use the `description` field).\n",
    "    4. Distribute the 3,000-word target across the sections, estimating a word count for each section (use the `words` field).\n",
    "    5. Base the outline solely on the provided materials, and ensure the sections appear in the order they would in the final article.\n",
    "    6. All outputs should be in English.\n",
    "    \"\"\"\n",
    "    outline_user_prompt = f\"Original summary and topics and summaries for expanded discussion：{documents}\"\n",
    "    response = llm_wrapper(outline_system_prompt, outline_user_prompt, OutlinesList)\n",
    "    sections = response.sections\n",
    "    return {\"sections_en\": sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491c0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_article_cn(state):\n",
    "    documents = state[\"documents\"]\n",
    "    sections = state[\"sections\"]\n",
    "    article = \"\"\n",
    "    write_sections = []\n",
    "    for section in sections:\n",
    "        write_system_prompt = f\"\"\"\n",
    "        你是一名美国续航教育公司专注于美国大学新闻的年轻评论员（25岁上下，女性，来自中国并在美国大学研究生毕业），你的评论风格偏向于年轻化、轻松化，\\\n",
    "            你习惯称呼自己为小编，并会在评论文章中加入自己独到的见解。你的用词多样富有变化，不平淡，让AI检测工具无法检测到文章为AI创作。\\\n",
    "                你将收到新闻标题、链接和新闻摘要，以及相关讨论的主题和相关文章的链接及其摘要。使用这些材料，按照提供给你的部分写作大纲，\\\n",
    "            撰写评论文章中的一个部分。确保你的部分符合以下要求：{section.description}，并且字数限制在约{section.words}以内。\n",
    "        重要提示：\n",
    "        1. 如果该部分不是结论，请避免做出总结性陈述。\n",
    "        2. 内容中不要包含任何标题。\n",
    "        3. 最终输出内容用中文输出。\n",
    "        4. 参考文章总体的写作大纲以及已经完成的文章部分，确保你的该部分内容与整体结构一致，同时确保内容的连贯性。\n",
    "        5. 注意用词的多样性，使文章看起来更加自然且更加接近自然人类语言。\n",
    "        \"\"\"\n",
    "        write_user_prompt = f\"原始新闻及相关讨论主题的材料：{documents}，全文的写作大纲：{sections}，文章已经完成的部分：{article}\"\n",
    "        response = llm_wrapper(write_system_prompt, write_user_prompt)\n",
    "        write_sections = write_sections + [\n",
    "            {\"title\": section.title, \"content\": response}\n",
    "        ]\n",
    "        article = article + \"\\n\\n\" + response\n",
    "        print(section.title, \"--------section done!\")\n",
    "    return {\"write_sections\": write_sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af4e9c-d3bd-4060-88f9-a45c9940b346",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_article_en(state):\n",
    "    documents = state[\"documents\"]\n",
    "    sections = state[\"sections_en\"]\n",
    "    article = \"\"\n",
    "    write_sections = []\n",
    "    for section in sections:\n",
    "        write_system_prompt = f\"\"\"\n",
    "        You are a commentator specializing in news about U.S. universities. You will be given a headline, link, and summary of the original news piece, \\\n",
    "        along with topics for further discussion and links to related articles with their summaries. Using these materials, write one section of the \\\n",
    "            commentary article following the writing outline provided below. Ensure that your section adheres to the specific requirements of the \\\n",
    "                description: {section.description}. The section stays within the word count limit of approximately {section.words}.\n",
    "        Important:\n",
    "        1. If the section is not the conclusion, avoid making concluding statements.\n",
    "        2. Do not include any headings in the content.\n",
    "        3. The final output should be in English.\n",
    "        4. Refer to the overall writing outline and completed sections of the article to ensure that your section aligns with the overall structure \\\n",
    "            and maintains content coherence.\n",
    "        5. Pay attention to word variety to make the article appear more natural and closer to human language.\n",
    "        \"\"\"\n",
    "        write_user_prompt = f\"\"\"Original summary and topics and summaries for expanded discussion: {documents}\\n\\n\n",
    "                                Full writing outline: {sections}\\n\\n\n",
    "                                Completed sections of the article: {article}\"\"\"\n",
    "        response = llm_wrapper(write_system_prompt, write_user_prompt)\n",
    "        write_sections = write_sections + [\n",
    "            {\"title\": section.title, \"content\": response}\n",
    "        ]\n",
    "        article = article + \"\\n\\n\" + response\n",
    "        print(section.title, \"--------section done!\")\n",
    "    return {\"write_sections_en\": write_sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1edf3dd7-1b2c-49a8-82fb-1ddd0396f615",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_reference(state):\n",
    "    documents = state[\"documents\"]\n",
    "    sections = state[\"sections\"]\n",
    "    sections_en = state[\"sections_en\"]\n",
    "    write_sections = state[\"write_sections\"]\n",
    "    write_sections_en = state[\"write_sections_en\"]\n",
    "    content_cn = \"\"\n",
    "    content_en = \"\"\n",
    "    section_number = 0\n",
    "    section_number_cn = len(write_sections) // 2 - 1\n",
    "    section_number_en = len(write_sections_en) // 2 - 1\n",
    "    for section in sections:\n",
    "        for write_section in write_sections:\n",
    "            if write_section[\"title\"] == section.title:\n",
    "                if section_number == section_number_cn:\n",
    "                    content_cn = (\n",
    "                        content_cn\n",
    "                        + \"###\"\n",
    "                        + write_section[\"title\"]\n",
    "                        + \"\\n\\n\"\n",
    "                        + image_insert_fuc(write_section[\"content\"])\n",
    "                        + \"\\n\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    content_cn = (\n",
    "                        content_cn\n",
    "                        + \"###\"\n",
    "                        + write_section[\"title\"]\n",
    "                        + \"\\n\\n\"\n",
    "                        + write_section[\"content\"]\n",
    "                        + \"\\n\\n\"\n",
    "                    )\n",
    "                break\n",
    "        section_number = section_number + 1\n",
    "    section_number = 0\n",
    "    for section in sections_en:\n",
    "        for write_section in write_sections_en:\n",
    "            if write_section[\"title\"] == section.title:\n",
    "                if section_number == section_number_en:\n",
    "                    content_en = (\n",
    "                        content_en\n",
    "                        + \"###\"\n",
    "                        + write_section[\"title\"]\n",
    "                        + \"\\n\\n\"\n",
    "                        + image_insert_fuc(write_section[\"content\"])\n",
    "                        + \"\\n\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    content_en = (\n",
    "                        content_en\n",
    "                        + \"###\"\n",
    "                        + write_section[\"title\"]\n",
    "                        + \"\\n\\n\"\n",
    "                        + write_section[\"content\"]\n",
    "                        + \"\\n\\n\"\n",
    "                    )\n",
    "                break\n",
    "        section_number = section_number + 1\n",
    "\n",
    "    rewrite_system_message = \"\"\"你是一名专注于美国大学新闻的评论员。你将收到新闻标题、链接和新闻摘要，以及相关讨论的主题、相关文章链接及其摘要。\\\n",
    "        用户将提供一篇基于这些材料写好的文章。你的任务是根据提供的材料在文章末尾添加参考文献。确保只包含文章中直接引用过的来源，跳过没有直接引用过的资料来源。\\\n",
    "            最终输出结果的格式为引用的文章标题数字列表，并在标题上加上url超链接。输出内容仅包含参考文献，不包含任何标题或额外内容。\"\"\"\n",
    "    rewrite_user_prompt = f\"Original summary and topics and summaries for expanded discussion：{documents} \\n\\n 用户写的文章: {content_cn}\"\n",
    "    reference_cn = llm_wrapper(rewrite_system_message, rewrite_user_prompt)\n",
    "\n",
    "    rewrite_system_message = \"\"\"You are a commentator specializing in news about American universities. You will receive news titles, \\\n",
    "        links, and summaries, as well as related discussion topics, links to related articles, and their summaries. The user will provide \\\n",
    "            an article written based on these materials. Your task is to add references at the end of the article based on the provided materials. \\\n",
    "                Ensure that only sources directly cited in the article are included. Skip any sources that are not directly cited. \\\n",
    "                    The final output should be a numeric list of the titles of the cited articles, with each title hyperlinked to its URL. \\\n",
    "                        The output should only contain the references, without any headings or additional content.\"\"\"\n",
    "    rewrite_user_prompt = f\"Original summary and topics and summaries for expanded discussion：{documents} \\n\\n The written article: {content_en}\"\n",
    "    reference_en = llm_wrapper(rewrite_system_message, rewrite_user_prompt)\n",
    "\n",
    "    content_cn = content_cn + \"###参考资料：\\n\\n\" + reference_cn\n",
    "    content_en = content_en + \"###Reference: \\n\\n\" + reference_en\n",
    "    return {\"content\": content_cn, \"content_en\": content_en}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89016558-85c0-450f-8d23-7613f7097793",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def article_metas(state):\n",
    "    content = state[\"content\"]\n",
    "    meta_system_prmopt = \"\"\"请完成以下任务：\n",
    "                1. 根据下面给出的文章内容，为文章取一个合适的标题。标题需要有中文和英文两个版本，中文版标题长度在20到30个中文字，英文标题长度在10到20个英文单词，分别放入title和title_en。\n",
    "                2. 根据文章内容，生成一个详细的图像生成提示（image generation prompt），提示词应为英文，并注意使用不会违反“安全系统”的安全词汇。图像风格应基于文章内容，放入image_query。\n",
    "                3. 为上述图像生成提示生成一个英文的图像文件名，但不包含文件类型扩展名，放入image_filename。\n",
    "                4. 为上述图像生成alt text，中文和英文分别放出image_alt_text和image_alt_text_en。\n",
    "                4. 生成一些与文章内容相关的标签，标签同样需要有中文和英文两个版本，分别放入tags和tags_en。\"\"\"\n",
    "    meta_user_prompt = f\"下面是需要处理的文章内容：\\n\\n{content}\"\n",
    "    chain_n = 0\n",
    "    while True:\n",
    "        if chain_n > 3:\n",
    "            raise Exception(\"get article metas error with 3 trials\")\n",
    "        try:\n",
    "            response = llm_wrapper(meta_system_prmopt, meta_user_prompt, MetaFormat)\n",
    "            break\n",
    "        except:\n",
    "            chain_n += 1\n",
    "\n",
    "    tag_names = response.tags\n",
    "    tags = tags_to_IDs(tag_names)\n",
    "    tag_names_en = response.tags_en\n",
    "    tags_en = tags_to_IDs_en(tag_names_en)\n",
    "    return {\n",
    "        \"title\": response.title,\n",
    "        \"title_en\": response.title_en,\n",
    "        \"image_query\": response.image_query,\n",
    "        \"image_filename\": response.image_filename,\n",
    "        \"tags\": tags,\n",
    "        \"tags_en\": tags_en,\n",
    "        \"image_alt\": response.image_alt_text,\n",
    "        \"image_alt_en\": response.image_alt_text_en,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3babcedf-31fa-4bfa-9003-69627a21c839",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_image(state):\n",
    "    image_filename = state[\"image_filename\"]\n",
    "    image_folder = os.path.join(get_local_folder(), \"images\")\n",
    "    png_image = os.path.join(image_folder, image_filename + \".png\")\n",
    "    jpg_image = os.path.join(image_folder, image_filename + \".jpg\")\n",
    "    image_query = state[\"image_query\"]\n",
    "    try:\n",
    "        image_url = llm_image_wrapper(image_query)\n",
    "        urllib.request.urlretrieve(image_url, png_image)\n",
    "        with Image.open(png_image) as image:\n",
    "            image.save(jpg_image, optimized=True, quality=20)\n",
    "        os.remove(png_image)\n",
    "        response = post_wordpress_file(jpg_image, lang_type=\"cn\")\n",
    "        response = response.json()\n",
    "        image_ID = int(response.get(\"id\"))\n",
    "        image_url = response.get(\"guid\").get(\"rendered\")\n",
    "        response_en = post_wordpress_file(jpg_image, lang_type=\"en\")\n",
    "        response_en = response_en.json()\n",
    "        image_ID_en = int(response_en.get(\"id\"))\n",
    "        image_url_en = response_en.get(\"guid\").get(\"rendered\")\n",
    "        return {\n",
    "            \"image_ID\": image_ID,\n",
    "            \"image_url\": image_url,\n",
    "            \"image_ID_en\": image_ID_en,\n",
    "            \"image_url_en\": image_url_en,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\"image_ID\": -1, \"image_url\": \"\", \"image_ID_en\": -1, \"image_url_en\": \"\"}\n",
    "\n",
    "\n",
    "def publish_post(state):\n",
    "    title = state[\"title\"]\n",
    "    image_alt = state[\"image_alt\"]\n",
    "    image_ID = state[\"image_ID\"]\n",
    "    image_url = state[\"image_url\"]\n",
    "    tags = state[\"tags\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.com/wp-content/uploads/2024/06/fp_college_news_default.jpg\"\n",
    "        image_ID = 107009\n",
    "    content = state[\"content\"]\n",
    "    raw_content = content\n",
    "    if content.find(\"[image_placeholder]\") > 0:\n",
    "        content = content.replace(\n",
    "            \"[image_placeholder]\",\n",
    "            \"\"\"<img src=\"{}\" alt=\"{}\">\"\"\".format(image_url, image_alt),\n",
    "        )\n",
    "    else:\n",
    "        content = \"\"\"<img src=\"{}\" alt=\"{}\">\"\"\".format(image_url, image_alt) + content\n",
    "    content = markdown2.markdown(\n",
    "        content,\n",
    "        extras=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content)\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[3627],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"cn\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    post_ID = response.get(\"id\")\n",
    "    update_summary_qa(post_ID, raw_content)\n",
    "    return\n",
    "\n",
    "\n",
    "def publish_post_en(state):\n",
    "    title = state[\"title_en\"]\n",
    "    image_alt = state[\"image_alt_en\"]\n",
    "    image_ID = state[\"image_ID_en\"]\n",
    "    image_url = state[\"image_url_en\"]\n",
    "    tags = state[\"tags_en\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.us/wp-content/uploads/2024/07/fp_college_news_default.jpg\"\n",
    "        image_ID = 15899\n",
    "    content = state[\"content_en\"]\n",
    "    if content.find(\"[image_placeholder]\") > 0:\n",
    "        content = content.replace(\n",
    "            \"[image_placeholder]\",\n",
    "            \"\"\"<img src=\"{}\" alt=\"{}\">\"\"\".format(image_url, image_alt),\n",
    "        )\n",
    "    else:\n",
    "        content = \"\"\"<img src=\"{}\" alt=\"{}\">\\n\"\"\".format(image_url, image_alt) + content\n",
    "    content = markdown2.markdown(\n",
    "        content,\n",
    "        extras=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content, lang_type=\"en\")\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[9],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"en\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d97d8c7-e31a-4d3f-9914-1b44d7b250e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"summary_node\", summary)\n",
    "workflow.add_node(\"more_topics\", more_topics)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"write_outline_cn\", write_outline_cn)\n",
    "workflow.add_node(\"write_outline_en\", write_outline_en)\n",
    "workflow.add_node(\"write_article_cn\", write_article_cn)\n",
    "workflow.add_node(\"write_article_en\", write_article_en)\n",
    "workflow.add_node(\"add_reference\", add_reference)\n",
    "workflow.add_node(\"article_metas\", article_metas)\n",
    "workflow.add_node(\"generate_image\", generate_image)\n",
    "workflow.add_node(\"publish_post\", publish_post)\n",
    "workflow.add_node(\"publish_post_en\", publish_post_en)\n",
    "\n",
    "workflow.set_entry_point(\"summary_node\")\n",
    "workflow.add_edge(\"summary_node\", \"more_topics\")\n",
    "workflow.add_conditional_edges(\"more_topics\", topics_to_search, [\"web_search\"])\n",
    "workflow.add_edge(\"web_search\", \"write_outline_cn\")\n",
    "workflow.add_edge(\"web_search\", \"write_outline_en\")\n",
    "workflow.add_edge(\"write_outline_cn\", \"write_article_cn\")\n",
    "workflow.add_edge(\"write_outline_en\", \"write_article_en\")\n",
    "workflow.add_edge(\"write_article_cn\", \"add_reference\")\n",
    "workflow.add_edge(\"write_article_en\", \"add_reference\")\n",
    "workflow.add_edge(\"add_reference\", \"article_metas\")\n",
    "workflow.add_edge(\"article_metas\", \"generate_image\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post_en\")\n",
    "workflow.add_edge(\"publish_post\", END)\n",
    "workflow.add_edge(\"publish_post_en\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959ad15-7752-4986-8ed8-0cfc5d4620bd",
   "metadata": {},
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    IPImage(\n",
    "        app.get_graph(xray=1).draw_mermaid_png(\n",
    "            curve_style=CurveStyle.BASIS,\n",
    "            node_colors=NodeStyles(\n",
    "                first=\"fill:#FDFFB6\",\n",
    "                last=\"fill:#FFADAD\",\n",
    "                default=\"fill:#CAFFBF,line-height:1\",\n",
    "            ),\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        ),\n",
    "        width=300,\n",
    "    )\n",
    ")\n",
    "\n",
    "img = app.get_graph().draw_mermaid_png(\n",
    "    curve_style=CurveStyle.BASIS,\n",
    "    node_colors=NodeStyles(\n",
    "        first=\"fill:#FDFFB6\",\n",
    "        last=\"fill:#FFADAD\",\n",
    "        default=\"fill:#CAFFBF,line-height:1\",\n",
    "    ),\n",
    "    draw_method=MermaidDrawMethod.API,\n",
    ")\n",
    "with open(\"post_publish_flow_new.png\", \"wb\") as png:\n",
    "    png.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1dd4fed-1964-4fee-9bb7-9bc7a60d32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Initial Summary:  https://news.berkeley.edu/2024/10/30/project-2025-could-be-disastrous-for-the-climate-legal-scholars-are-preparing-to-fight-back/\n",
      "https://www.sierraclub.org/sierra/what-would-happen-science-if-national-oceanic-and-atmospheric-administration-were-broken  --- done!\n",
      "https://jacobin.com/2024/11/gop-republicans-environment-epa-regulations  --- done!\n",
      "https://news.berkeley.edu/2024/10/30/project-2025-could-be-disastrous-for-the-climate-legal-scholars-are-preparing-to-fight-back/  --- done!\n",
      "https://www.pbs.org/newshour/politics/court-upholds-californias-authority-to-set-nation-leading-vehicle-emission-rules  --- done!\n",
      "https://www.vox.com/climate/379450/election-2024-climate-stakes-presidential-race  --- done!\n",
      "https://www.latimes.com/environment/story/2024-07-28/project-2025-targets-noaa-and-national-weather-service  --- done!\n",
      "https://www.epa.gov/climate-change  --- done!\n",
      "https://www.nytimes.com/2024/10/12/climate/california-tries-trump-proofing-its-climate-policies.html  --- done!\n",
      "https://www.americanprogress.org/article/project-2025-would-jeopardize-global-climate-action/  --- done!\n",
      "https://www.news-press.com/story/opinion/2024/08/11/project-2025-threatens-floridas-climate-science-public-safety/74713450007/  --- done!\n",
      "https://www.eea.europa.eu/en/topics/in-depth/agriculture-and-food  --- done!\n",
      "https://www.ciel.org/the-end-of-environmental-protection-regulation-as-we-know-it/  --- done!\n",
      "https://yaleclimateconnections.org/2024/07/what-project-2025-would-do-to-climate-policy-in-the-us/  --- done!\n",
      "http://garamendi.house.gov/media/press-releases/california-congressional-delegation-calls-caltrans-eliminate-redundant-federal  --- done!\n",
      "https://www.washingtonpost.com/climate-environment/2024/07/01/supreme-court-climate-environmental-policy/  --- none response!\n",
      "https://www.nytimes.com/2024/06/29/climate/supreme-court-epa.html  --- done!\n",
      "引言：Project 2025的背景与影响 --------section done!\n",
      "Introduction to Project 2025 and Its Implications --------section done!\n",
      "The Threat to Federal Climate Agencies and Regulations --------section done!\n",
      "Project 2025对环境保护机构的威胁 --------section done!\n",
      "California的环境标准与联邦法规的冲突 --------section done!\n",
      "California's Environmental Leadership at Risk --------section done!\n",
      "法律与政策的对抗：应对Project 2025的策略 --------section done!\n",
      "结论：未来的展望与行动呼吁 --------section done!\n",
      "Legal Challenges and Counteractions to Project 2025 --------section done!\n",
      "The Global Implications of Project 2025 --------section done!\n",
      "https://news.berkeley.edu/2024/10/30/project-2025-could-be-disastrous-for-the-climate-legal-scholars-are-preparing-to-fight-back/ finished\n"
     ]
    }
   ],
   "source": [
    "urls = get_news_urls()\n",
    "for url in urls:\n",
    "    try:\n",
    "        app.invoke({\"url\": url})\n",
    "        set_news_url_flag(url)\n",
    "        print(url, \"finished\")\n",
    "    except Exception as e:\n",
    "        print(\"error for url: \", url)\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
