{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cab3aa-d600-4e0c-8b94-5b4064d75a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "from typing import List, Literal, TypedDict\n",
    "\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "from wordpress_tools import (\n",
    "    get_news_urls,\n",
    "    insert_keyword_url,\n",
    "    post_wordpress_file,\n",
    "    post_wordpress_post,\n",
    "    set_news_url_flag,\n",
    "    tags_to_IDs,\n",
    "    tags_to_IDs_en,\n",
    "    update_summary_qa,\n",
    ")\n",
    "\n",
    "# from langchain.docstore.document import Document\n",
    "model_small = \"gpt-4o-mini\"\n",
    "\n",
    "model_large = \"gpt-4o-mini\"\n",
    "\n",
    "llm_small = ChatOpenAI(model=model_small, temperature=0, timeout=40000)\n",
    "llm_large = ChatOpenAI(model=model_large, temperature=0, timeout=40000)\n",
    "# llm = ChatOpenAI()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"college-news-auto-post\"\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "MAX_WEB_URL = 5\n",
    "MAX_QUERY_RESULT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b31f868-5914-450c-8dc2-a4a003ad286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    url: str\n",
    "    summary: str\n",
    "    topics: List[str]\n",
    "    documents: str\n",
    "    image_query: str\n",
    "    title: str\n",
    "    title_en: str\n",
    "    content: str\n",
    "    content_en: str\n",
    "    tags: set\n",
    "    tags_en: set\n",
    "    image_url: str\n",
    "    image_url_en: str\n",
    "    image_ID: int\n",
    "    image_ID_en: int\n",
    "    image_filename: str\n",
    "    reference: dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e600995-2d8f-4e50-a722-6d33d006439d",
   "metadata": {},
   "source": [
    "url=\"https://news.wm.edu/2024/07/18/plankton-researchers-urge-their-colleagues-to-mix-it-up/\"\n",
    "loader = WebBaseLoader(\n",
    "            url, requests_kwargs={\"timeout\": 10}, raise_for_status=True\n",
    "        )\n",
    "loader.requests_kwargs = {\"verify\": False}\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e0c942-2c1f-4f2c-a63b-71682195898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_output(BaseModel):\n",
    "    title: str = Field(description=\"网页内容总结标题，标题的语言必须是英文\")\n",
    "    summary: str = Field(description=\"网页内容总结内容，总结内容的语言必须是中文\")\n",
    "\n",
    "\n",
    "def summary_from_url(url):\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "    loader =SeleniumURLLoader(urls=[])\n",
    "    docs=loader.load()\n",
    "    \"\"\"\n",
    "    summary_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"任务说明：你是一名专业的新闻总结员。请根据下面给出的网页内容，总结出一段约800个汉字的新闻摘要。摘要必须使用中文，内容需全面，字数大约在800个汉字左右。\n",
    "                具体要求：\n",
    "                1. 新闻摘要：提炼新闻的核心内容，确保信息全面且连贯。字数大约在800个汉字左右。\n",
    "                2. 标题提取：如果网页内容中已有标题，请提取该标题。如果没有标题，请根据内容总结一个合适的标题。标题必须是英文。\n",
    "                3. 日期信息：如果网页内容中包含新闻发布日期，请在新闻摘要中包含该日期，日期格式需包含年份。\n",
    "                4. 美国大学相关内容：如果网页内容中提到美国大学（比如哈佛大学、耶鲁大学等等），只要提到了就请在新闻摘要中包含该大学的相关信息（比如与网页内容事件相关或者与作者相关等等）。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"网页内容: {content}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        loader = WebBaseLoader(\n",
    "            url, requests_kwargs={\"timeout\": 10}, raise_for_status=True\n",
    "        )\n",
    "        loader.requests_kwargs = {\"verify\": False}\n",
    "        docs = loader.load()\n",
    "        content = docs[0].page_content\n",
    "        encoding = tiktoken.encoding_for_model(model_small)\n",
    "        token_length = len(encoding.encode(content))\n",
    "        if token_length <= 15000:\n",
    "            structured_llm = llm_small.with_structured_output(summary_output)\n",
    "        else:\n",
    "            structured_llm = llm_large.with_structured_output(summary_output)\n",
    "        summary_chain = summary_prompt | structured_llm\n",
    "        response = summary_chain.invoke({\"content\": content})\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404 or e.response.status_code == 403:\n",
    "            response = \"404\"\n",
    "        else:\n",
    "            response = None\n",
    "    except:\n",
    "        response = None\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c397edf-8768-42f7-a657-f94834ad31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    url = state[\"url\"]\n",
    "    response = summary_from_url(url)\n",
    "    if response == \"404\":\n",
    "        set_news_url_flag(url)\n",
    "        raise Exception(\"Orginal url 403/404 error\")\n",
    "    title = response.title\n",
    "    summary = response.summary\n",
    "    print(\"Finish Initial Summary: \", url)\n",
    "    url_base = url.split(\"?\")[0]\n",
    "    return {\"summary\": summary, \"reference\": {url_base: title}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5785bf-d1e7-4db8-9796-46db2331b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class more_points(BaseModel):\n",
    "    more: list[str] = Field(\n",
    "        description=\"可以展开讨论的点的搜索查询，必须是英文搜索查询\"\n",
    "    )\n",
    "\n",
    "\n",
    "def more_topics(state):\n",
    "    summary = state[\"summary\"]\n",
    "    structured_llm = llm_large.with_structured_output(more_points)\n",
    "    more_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"从下面用户给出的一段原始总结文字中提出不少于'两'点但不多于'四'点与原文有联系且可以展开讨论的点, 请给出详细的搜索查询来代表这几个点，搜索查询必须要完整且详细，\n",
    "                搜索查询必须为英文，不管输入内容是什么语言，输出的搜索查询必须是英文查询。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"原始总结文字：{summary}\"),\n",
    "        ]\n",
    "    )\n",
    "    more_chain = more_prompt | structured_llm\n",
    "    topics = more_chain.invoke({\"summary\": summary})\n",
    "    return {\"topics\": topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933f7ba9-6ccb-471d-a6e7-b986154a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    search = GoogleSerperAPIWrapper(type=\"news\")\n",
    "    queries = state[\"topics\"].more\n",
    "    reference = state[\"reference\"]\n",
    "    documents = \"\"\n",
    "    n_urls = 0\n",
    "    for query in queries:\n",
    "        if n_urls >= MAX_WEB_URL:\n",
    "            break\n",
    "        results = search.results(query)\n",
    "        n_results = 0\n",
    "        for result in results[\"news\"]:\n",
    "            url = result[\"link\"]\n",
    "            url_base = url.split(\"?\")[0]\n",
    "            if url_base in reference:\n",
    "                continue\n",
    "            else:\n",
    "                print(\"------ Topics Summary: \", url,end=\" \")\n",
    "                response = summary_from_url(url)\n",
    "                if response is None:\n",
    "                    print ('none response!')\n",
    "                    continue\n",
    "                elif response=='404':\n",
    "                    print ('403/404 response')\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"done!\")\n",
    "                    doc = response.summary\n",
    "                    title = response.title\n",
    "                    reference[url_base] = title\n",
    "                    documents = documents + query + \"\\n\\n\" + doc + \"\\n\\n\"\n",
    "                    n_urls = n_urls + 1\n",
    "                    n_results = n_results + 1\n",
    "                    if n_results >= MAX_QUERY_RESULT:\n",
    "                        break\n",
    "    return {\"documents\": documents, \"reference\": reference}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cbcf86-74c8-4a8c-ad91-1f172cc2f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    summary = state[\"summary\"]\n",
    "    documents = state[\"documents\"]\n",
    "    topics = state[\"topics\"].more\n",
    "    content_array = []\n",
    "    content_set = {}\n",
    "    repeat_N = 0\n",
    "    system_message = \"\"\"任务说明：你的角色是一名专业的美国大学新闻评论员，下面给出一段原始总结内容，同时提供了一些可以扩展讨论的点和支持这些讨论点的材料。\\\n",
    "    请重新撰写一篇2000-4000字的评论文章。字数可以根据内容的多少适当选择，但不能少于2000字且不能超过4000字。\n",
    "    文章要求：\n",
    "    1. 内容围绕原始总结：评论文章内容应主要围绕原始总结展开，对与美国大学相关的内容要额外关注。\n",
    "    2. 扩展讨论：结合提供的讨论点进行扩展讨论。扩展讨论时需要前后呼应，提及与原始总结相关联的内容。如果扩展讨论点及其支持材料与原始总结内容无关或无法一起讨论，\\\n",
    "    可以舍弃这些扩展讨论点和内容，并将重心放在与原始总结有关的讨论上。如果扩展讨论点及支持材料有重复内容的请只使用一次该内容。\n",
    "    3. 连贯的逻辑关系：文章前后的逻辑关系需要连贯。如果有需要，可以重写全文，使其更加流畅。\n",
    "    4. 美国大学名称使用规范：\n",
    "    - 第一次提及美国大学名称时，必须使用该大学的中文全名，之后可以适当使用缩写。\n",
    "    - 美国大学全名需使用最普遍的中文翻译版本。\n",
    "    - 加利福尼亚大学各个分校一律使用“加州大学+分校名称”，例如加州大学尔湾分校。\n",
    "    - 加州大学欧文分校请使用加州大学尔湾分校。\n",
    "    - 布兰戴斯大学请使用布兰迪斯大学。\n",
    "    - 威廉与玛丽学院和威廉与玛丽大学请使用威廉玛丽学院。\n",
    "    - 利哈伊大学请使用里海大学。\n",
    "    - 密歇根大学安娜堡分校需使用全称，不能缩写成密歇根大学。\n",
    "    - 伊利诺伊大学香槟分校需使用全称，不能缩写成伊利诺伊大学。\n",
    "    - 乔治亚大学请使用佐治亚大学。\n",
    "    - 华盛顿大学圣路易斯分校请用圣路易斯华盛顿大学。\n",
    "    5. 输出只包含正文：输出的文章评论不要包含文章标题。\n",
    "    6. 图片空位：在文章中合适的位置，尽量在文章中上部位且在两个段落之间，需放置一个且必须有一个图片空位，用'[image_placeholder]'代表这个图片空位。\"\"\"\n",
    "    while len(content_array) == 0 or (len(content_array) - len(content_set)) > 0:\n",
    "        if repeat_N >= 4:\n",
    "            local_folder = get_local_folder()\n",
    "            file = os.path.join(get_local_folder(), \"repeat.txt\")\n",
    "            f = open(file, \"a\")\n",
    "            f.write(\n",
    "                state[\"url\"]\n",
    "                + \"\\n\\n---------------------------------------------------------------------\\n\\n\"\n",
    "            )\n",
    "            f.close()\n",
    "            raise Exception(\"rewrite CN version 4 times still get duplicates\")\n",
    "            break\n",
    "        rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_message),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"原始总结内容：\\n\\n{summary},\\n\\n扩展讨论点：\\n\\n{topics},\\n\\n支持扩展讨论点的讨论：\\n\\n{documents}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        rewrite_chain = rewrite_prompt | llm_large | StrOutputParser()\n",
    "        content = rewrite_chain.invoke(\n",
    "            {\"summary\": summary, \"topics\": topics, \"documents\": documents}\n",
    "        )\n",
    "        content_array = content.split(\"\\n\\n\")\n",
    "        for element in content_array:\n",
    "            if len(element) <= 20:\n",
    "                content_array.remove(element)\n",
    "        content_set = set(content_array)\n",
    "        repeat_N = repeat_N + 1\n",
    "        system_message = (\n",
    "            system_message\n",
    "            + \"\\n\\n新的文章不要有重复的段落，如果遇到原始总结内容和扩展讨论点有重复内容的可以忽略重复内容，在最后的输出文章中不可以有重复段落。\"\n",
    "        )\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d0eb04-bdb6-4d2f-8529-85798f30a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_en(state):\n",
    "    summary = state[\"summary\"]\n",
    "    documents = state[\"documents\"]\n",
    "    topics = state[\"topics\"].more\n",
    "    content_array = []\n",
    "    content_set = {}\n",
    "    repeat_N = 0\n",
    "    system_message = \"\"\"Your role is a professional American university news commentator. Below is an original summary along with some discussion points and supporting arguments to expand upon.\\\n",
    "    Please rewrite a 2000-4000 word commentary article, with the word count adjusted according to the content, but not less than 2000 words and not more than 4000 words.\\\n",
    "    The commentary should center around the original summary, with extra focus on content related to U.S. colleges. Appropriately integrate the discussion points and their \\\n",
    "    supporting arguments into your expanded discussion. Ensure to consistently refer back to the original summary when expanding your discussion. \\\n",
    "    Conclude with a comprehensive summary that ties together the original summary and the expanded discussion. The logical flow of the article must be coherent, \\\n",
    "    and the entire text may be rewritten if necessary. When mentioning the names of U.S. colleges for the first time, always use the full English name. \\\n",
    "    Subsequent mentions can use abbreviations where appropriate. Use the most commonly recognized English version of the full names. \\\n",
    "    For campuses, use a hyphen to connect, such as University of California-Berkeley.\n",
    "    For headings, start from h2 headings, the output should only contain content without title, and there should be no h1 heading in the output.\n",
    "    In a suitable position within the article, preferably towards the upper-middle and between two paragraphs, include one image placeholder represented by '[image_placeholder]'.\n",
    "    The final output must be in English, regardless of any other considerations.\"\"\"\n",
    "    while len(content_array) == 0 or (len(content_array) - len(content_set)) > 0:\n",
    "        rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_message),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"Original summary：\\n\\n{summary},\\n\\nDiscussion Points：\\n\\n{topics},\\n\\nsupporting arguments：\\n\\n{documents}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        rewrite_chain = rewrite_prompt | llm_large | StrOutputParser()\n",
    "        content = rewrite_chain.invoke(\n",
    "            {\"summary\": summary, \"topics\": topics, \"documents\": documents}\n",
    "        )\n",
    "        content_array = content.split(\"\\n\\n\")\n",
    "        for element in content_array:\n",
    "            if len(element) <= 20:\n",
    "                content_array.remove(element)\n",
    "        content_set = set(content_array)\n",
    "        repeat_N = repeat_N + 1\n",
    "        if repeat_N >= 4:\n",
    "            local_folder = get_local_folder()\n",
    "            file = os.path.join(get_local_folder(), \"repeat.txt\")\n",
    "            f = open(file, \"a\")\n",
    "            f.write(\n",
    "                state[\"url\"]\n",
    "                + \"\\n\\n---------------------------------------------------------------------\\n\\n\"\n",
    "            )\n",
    "            f.close()\n",
    "            raise Exception(\"rewrite EN version 4 times still get duplicates\")\n",
    "            break\n",
    "        system_message = (\n",
    "            system_message\n",
    "            + \"\\n\\n新的文章不要有重复的段落，如果遇到原始总结内容和扩展讨论点有重复内容的可以忽略重复内容，在最后的输出文章中不可以有重复段落。\"\n",
    "        )\n",
    "    return {\"content_en\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89016558-85c0-450f-8d23-7613f7097793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_format(BaseModel):\n",
    "    title: str = Field(description=\"与文章内容相关的文章中文标题，用中文输出\")\n",
    "    title_en: str = Field(description=\"与文章内容相关的文章英文标题，用英文输出\")\n",
    "    image_query: str = Field(\n",
    "        description=\"detailed prompt to generate an image that based on the article content, should be in English\"\n",
    "    )\n",
    "    image_filename: str = Field(\n",
    "        description=\"a good name for the image file without file extension, should be in English\"\n",
    "    )\n",
    "    tags: List[str] = Field(description=\"与文章内容相关的中文标签，用中文输出\")\n",
    "    tags_en: List[str] = Field(description=\"与文章内容相关的英文标签，用英文输出\")\n",
    "\n",
    "\n",
    "def article_metas(state):\n",
    "    content = state[\"content\"]\n",
    "    meta_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"请完成以下任务：\n",
    "                1. 根据下面给出的文章内容，为文章取一个合适的标题。标题需要有中文和英文两个版本。\n",
    "                2. 根据文章内容，生成一个详细的图像生成提示（image generation prompt），提示词应为英文，并注意使用不会违反“安全系统”的安全词汇。图像风格应基于文章内容。\n",
    "                3. 为上述图像生成提示生成一个英文的图像文件名，但不包含文件类型扩展名。\n",
    "                4. 生成一些与文章内容相关的标签，标签同样需要有中文和英文两个版本。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"下面是需要处理的文章内容：\\n\\n{content}\"),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm_large.with_structured_output(meta_format)\n",
    "    meta_chain = meta_prompt | structured_llm\n",
    "    chain_n = 0\n",
    "    while True:\n",
    "        if chain_n > 3:\n",
    "            raise Exception(\"get article metas error with 3 trials\")\n",
    "        try:\n",
    "            response = meta_chain.invoke({\"content\": content})\n",
    "            break\n",
    "        except:\n",
    "            chain_n += 1\n",
    "\n",
    "    tag_names = response.tags\n",
    "    tags = tags_to_IDs(tag_names)\n",
    "    tag_names_en = response.tags_en\n",
    "    tags_en = tags_to_IDs_en(tag_names_en)\n",
    "    return {\n",
    "        \"title\": response.title,\n",
    "        \"title_en\": response.title_en,\n",
    "        \"image_query\": response.image_query,\n",
    "        \"image_filename\": response.image_filename,\n",
    "        \"tags\": tags,\n",
    "        \"tags_en\": tags_en,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3babcedf-31fa-4bfa-9003-69627a21c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(state):\n",
    "    image_filename = state[\"image_filename\"]\n",
    "    image_folder = os.path.join(get_local_folder(), \"images\")\n",
    "    png_image = os.path.join(image_folder, image_filename + \".png\")\n",
    "    jpg_image = os.path.join(image_folder, image_filename + \".jpg\")\n",
    "    image_query = state[\"image_query\"]\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(\n",
    "            model=\"dall-e-3\", size=\"1792x1024\", quality=\"standard\"\n",
    "        ).run(image_query)\n",
    "        urllib.request.urlretrieve(image_url, png_image)\n",
    "        with Image.open(png_image) as image:\n",
    "            image.save(jpg_image, optimized=True, quality=20)\n",
    "        os.remove(png_image)\n",
    "        response = post_wordpress_file(jpg_image, lang_type=\"cn\")\n",
    "        response = response.json()\n",
    "        image_ID = int(response.get(\"id\"))\n",
    "        image_url = response.get(\"guid\").get(\"rendered\")\n",
    "        response_en = post_wordpress_file(jpg_image, lang_type=\"en\")\n",
    "        response_en = response_en.json()\n",
    "        image_ID_en = int(response_en.get(\"id\"))\n",
    "        image_url_en = response_en.get(\"guid\").get(\"rendered\")\n",
    "        return {\n",
    "            \"image_ID\": image_ID,\n",
    "            \"image_url\": image_url,\n",
    "            \"image_ID_en\": image_ID_en,\n",
    "            \"image_url_en\": image_url_en,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\"image_ID\": -1, \"image_url\": \"\", \"image_ID_en\": -1, \"image_url_en\": \"\"}\n",
    "\n",
    "\n",
    "def publish_post(state):\n",
    "    title = state[\"title\"]\n",
    "    image_ID = state[\"image_ID\"]\n",
    "    image_url = state[\"image_url\"]\n",
    "    tags = state[\"tags\"]\n",
    "    reference = state[\"reference\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.com/wp-content/uploads/2024/06/fp_college_news_default.jpg\"\n",
    "        image_ID = 107009\n",
    "    content = state[\"content\"]\n",
    "    raw_content = content\n",
    "    content = content + \"\"\"\\n### 参考新闻资料:\"\"\"\n",
    "    for key in reference:\n",
    "        content = content + \"\"\"\\n1. [{}]({})\"\"\".format(reference[key], key)\n",
    "    content = markdown.markdown(\n",
    "        content.replace(\"[image_placeholder]\", \"\"\"<img src=\"{}\">\"\"\".format(image_url)),\n",
    "        extensions=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content)\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[3627],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"cn\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    post_ID = response.get(\"id\")\n",
    "    update_summary_qa(post_ID, raw_content, llm_small)\n",
    "    return\n",
    "\n",
    "\n",
    "def publish_post_en(state):\n",
    "    title = state[\"title_en\"]\n",
    "    image_ID = state[\"image_ID_en\"]\n",
    "    image_url = state[\"image_url_en\"]\n",
    "    tags = state[\"tags_en\"]\n",
    "    reference = state[\"reference\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.us/wp-content/uploads/2024/07/fp_college_news_default.jpg\"\n",
    "        image_ID = 15899\n",
    "    content = state[\"content_en\"]\n",
    "    content = content + \"\"\"\\n### News References:\"\"\"\n",
    "    for key in reference:\n",
    "        content = content + \"\"\"\\n1. [{}]({})\"\"\".format(reference[key], key)\n",
    "    content = markdown.markdown(\n",
    "        content.replace(\"[image_placeholder]\", \"\"\"<img src=\"{}\">\"\"\".format(image_url)),\n",
    "        extensions=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content, lang_type=\"en\")\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[9],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"en\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    post_ID = response.get(\"id\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d97d8c7-e31a-4d3f-9914-1b44d7b250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"summary_node\", summary)\n",
    "workflow.add_node(\"more_topics\", more_topics)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"rewrite_en\", rewrite_en)\n",
    "workflow.add_node(\"article_metas\", article_metas)\n",
    "# workflow.add_node(\"format_article\", format_article)\n",
    "workflow.add_node(\"generate_image\", generate_image)\n",
    "workflow.add_node(\"publish_post\", publish_post)\n",
    "workflow.add_node(\"publish_post_en\", publish_post_en)\n",
    "\n",
    "workflow.set_entry_point(\"summary_node\")\n",
    "workflow.add_edge(\"summary_node\", \"more_topics\")\n",
    "workflow.add_edge(\"more_topics\", \"web_search\")\n",
    "workflow.add_edge(\"web_search\", \"rewrite\")\n",
    "workflow.add_edge(\"rewrite\", \"rewrite_en\")\n",
    "workflow.add_edge(\"rewrite_en\", \"article_metas\")\n",
    "workflow.add_edge(\"article_metas\", \"generate_image\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post\")\n",
    "workflow.add_edge(\"publish_post\", \"publish_post_en\")\n",
    "workflow.add_edge(\"publish_post_en\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e480956-4fc3-4472-95a6-471f83661a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# display(Image(app.get_graph().draw_mermaid_png(),width=300))\n",
    "# img=app.get_graph().draw_mermaid_png()\n",
    "# with open('GraphFlow.png','wb') as png:\n",
    "#    png.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64236d7d-b439-46b0-b352-71e34f2e6b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Initial Summary:  https://news.wm.edu/2024/07/18/plankton-researchers-urge-their-colleagues-to-mix-it-up/\n",
      "------ Topics Summary:  https://www.eurekalert.org/news-releases/1049450 done!\n",
      "------ Topics Summary:  https://news.wm.edu/2024/07/09/plankton-researchers-urge-their-colleagues-to-mix-it-up/ 404 response\n",
      "------ Topics Summary:  https://www.frontiersin.org/journals/marine-science/articles/10.3389/fmars.2021.740763/full done!\n",
      "------ Topics Summary:  https://www.nature.com/articles/s41598-023-33962-x done!\n",
      "1 finished\n"
     ]
    }
   ],
   "source": [
    "urls = get_news_urls()\n",
    "n_url = 0\n",
    "for url in urls:\n",
    "    try:\n",
    "        app.invoke({\"url\": url})\n",
    "        set_news_url_flag(url)\n",
    "        n_url = n_url + 1\n",
    "        print(n_url, \"finished\")\n",
    "    except Exception as e:\n",
    "        print(\"error for url: \", url)\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
