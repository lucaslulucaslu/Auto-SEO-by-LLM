{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cab3aa-d600-4e0c-8b94-5b4064d75a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "import urllib.request\n",
    "from typing import Annotated, List, Literal, TypedDict\n",
    "\n",
    "import markdown2\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph\n",
    "from LLM_get_folder import get_local_folder\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field\n",
    "from wordpress_tools import (\n",
    "    get_news_urls,\n",
    "    insert_keyword_url,\n",
    "    post_wordpress_file,\n",
    "    post_wordpress_post,\n",
    "    set_news_url_flag,\n",
    "    tags_to_IDs,\n",
    "    tags_to_IDs_en,\n",
    "    update_summary_qa,\n",
    ")\n",
    "\n",
    "# from langchain.docstore.document import Document\n",
    "model_small = \"gpt-4o-mini\"\n",
    "\n",
    "model_large = \"gpt-4o-mini\"\n",
    "\n",
    "llm_small = ChatOpenAI(model=model_small, temperature=0, timeout=40000)\n",
    "llm_large = ChatOpenAI(model=model_large, temperature=0, timeout=40000)\n",
    "# llm = ChatOpenAI()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"college-news-auto-post\"\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "MAX_WEB_URL = 5\n",
    "MAX_QUERY_RESULT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b31f868-5914-450c-8dc2-a4a003ad286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class documentType(BaseModel):\n",
    "    topic: str\n",
    "    url: str\n",
    "    title: str\n",
    "    summary: str\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    url: str\n",
    "    summary: str\n",
    "    topics: list[str]\n",
    "    documents: Annotated[list[documentType], operator.add]\n",
    "    image_query: str\n",
    "    title: str\n",
    "    title_en: str\n",
    "    content: str\n",
    "    content_en: str\n",
    "    tags: set\n",
    "    tags_en: set\n",
    "    image_url: str\n",
    "    image_url_en: str\n",
    "    image_ID: int\n",
    "    image_ID_en: int\n",
    "    image_filename: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e0c942-2c1f-4f2c-a63b-71682195898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_output(BaseModel):\n",
    "    title: str = Field(description=\"网页内容总结标题，标题的语言必须是英文\")\n",
    "    summary: str = Field(description=\"网页内容总结内容，总结内容的语言必须是中文\")\n",
    "\n",
    "\n",
    "def summary_from_url(url):\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "    loader =SeleniumURLLoader(urls=[])\n",
    "    docs=loader.load()\n",
    "    \"\"\"\n",
    "    summary_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"任务说明：你是一名专业的新闻总结员。请根据下面给出的网页内容，总结出一段约800个汉字的新闻摘要。摘要必须使用中文，内容需全面，字数大约在800个汉字左右。\n",
    "                具体要求：\n",
    "                1. 新闻摘要：提炼新闻的核心内容，确保信息全面且连贯。字数大约在800个汉字左右。\n",
    "                2. 标题提取：如果网页内容中已有标题，请提取该标题。如果没有标题，请根据内容总结一个合适的标题。标题必须是英文。\n",
    "                3. 日期信息：如果网页内容中包含新闻发布日期，请在新闻摘要中包含该日期，日期格式需包含年份。\n",
    "                4. 美国大学相关内容：如果网页内容中提到美国大学（比如哈佛大学、耶鲁大学等等），只要提到了就请在新闻摘要中包含该大学的相关信息（比如与网页内容事件相关或者与作者相关等等）。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"网页内容: {content}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        loader = WebBaseLoader(\n",
    "            url, requests_kwargs={\"timeout\": 10}, raise_for_status=True\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        content = docs[0].page_content\n",
    "        structured_llm = llm_large.with_structured_output(\n",
    "            summary_output, method=\"json_schema\"\n",
    "        )\n",
    "        summary_chain = summary_prompt | structured_llm\n",
    "        response = summary_chain.invoke({\"content\": content})\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404 or e.response.status_code == 403:\n",
    "            response = \"404\"\n",
    "        else:\n",
    "            response = None\n",
    "    except:\n",
    "        response = None\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c397edf-8768-42f7-a657-f94834ad31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    url = state[\"url\"]\n",
    "    response = summary_from_url(url)\n",
    "    if response is None:\n",
    "        set_news_url_flag(url)\n",
    "        raise Exception(\"Orginal url None error\")\n",
    "    if response == \"404\":\n",
    "        set_news_url_flag(url)\n",
    "        raise Exception(\"Orginal url 403/404 error\")\n",
    "    title = response.title\n",
    "    summary = response.summary\n",
    "    print(\"Finish Initial Summary: \", url)\n",
    "    url_base = url.split(\"?\")[0]\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"topic\": \"原始文章总结，This is the initial article summary.\",\n",
    "                \"url\": url_base,\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "            }\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5785bf-d1e7-4db8-9796-46db2331b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class more_points(BaseModel):\n",
    "    more: list[str] = Field(\n",
    "        description=\"可以展开讨论的话题的搜索查询短句，必须是英文搜索查询短句，the output search query should be in purely English.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def more_topics(state):\n",
    "    summary = state[\"summary\"]\n",
    "    structured_llm = llm_large.with_structured_output(more_points, method=\"json_schema\")\n",
    "    more_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"从下面用户给出的一段原始总结文字中提出五个与原文有联系且可以展开讨论的话题, 请给出详细的搜索查询来代表这几个讨论话题，搜索查询必须要完整且详细，\n",
    "                搜索查询必须为英文，不管输入内容是什么语言，输出的搜索查询短句必须是英文查询短句，the output search query should be in purely English。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"原始总结文字：{summary}\"),\n",
    "        ]\n",
    "    )\n",
    "    more_chain = more_prompt | structured_llm\n",
    "    topics = more_chain.invoke({\"summary\": summary}).more\n",
    "    return {\"topics\": topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e90b592-d50e-4c7c-8566-1fda5443d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_to_search(state):\n",
    "    return [Send(\"web_search\", {\"query\": topic}) for topic in state[\"topics\"][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933f7ba9-6ccb-471d-a6e7-b986154a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class webSearchState(TypedDict):\n",
    "    query: str\n",
    "\n",
    "\n",
    "def web_search(state: webSearchState):\n",
    "    search = GoogleSerperAPIWrapper(type=\"news\")\n",
    "    query = state[\"query\"]\n",
    "    results = search.results(query)\n",
    "    n_results = 0\n",
    "    documents = []\n",
    "    for result in results[\"news\"]:\n",
    "        if n_results >= MAX_QUERY_RESULT:\n",
    "            break\n",
    "        url = result[\"link\"]\n",
    "        response = summary_from_url(url)\n",
    "        if response is None:\n",
    "            print(url, \" --- none response!\")\n",
    "            continue\n",
    "        elif response == \"404\":\n",
    "            print(url, \" --- 403/404 response\")\n",
    "            continue\n",
    "        else:\n",
    "            print(url, \" --- done!\")\n",
    "            summary = response.summary\n",
    "            title = response.title\n",
    "            documents = documents + [\n",
    "                {\"topic\": query, \"url\": url, \"title\": title, \"summary\": summary}\n",
    "            ]\n",
    "            n_results = n_results + 1\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cbcf86-74c8-4a8c-ad91-1f172cc2f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    summary = state[\"summary\"]\n",
    "    documents = state[\"documents\"]\n",
    "    topics = state[\"topics\"]\n",
    "    content_array = []\n",
    "    content_set = {}\n",
    "    repeat_N = 0\n",
    "    system_message = \"\"\"任务说明： 你的角色是一名专业的美国大学新闻评论员。下方提供了一段原始新闻总结内容，以及一些可供扩展讨论的话题和支持材料。请根据这些信息撰写一篇2000-5000字的评论文章。具体要求如下：\n",
    "1. 内容围绕原始总结： 文章应以原始新闻总结为核心展开，特别关注与美国大学相关的内容。\n",
    "2. 扩展讨论： 在评论文章中，结合提供的话题进行扩展讨论。扩展时，需确保前后呼应，并与原始总结内容相连。如果某些扩展讨论话题或支持材料与原始总结不相关或难以整合，可以舍弃这些内容，将重心放在相关讨论上。\\\n",
    "此外，如果扩展内容中存在重复，请只使用一次。\n",
    "3. 逻辑连贯： 文章前后逻辑应保持连贯。如果必要，可以对全文进行重写，使其更加流畅和连贯。\n",
    "4. 美国大学名称使用规范：\n",
    "    第一次提及美国大学名称时，必须使用该大学的中文全名，后续可使用适当的缩写。\n",
    "    美国大学全名需使用最普遍的中文翻译版本。\n",
    "    加利福尼亚大学各个分校请使用“加州大学+分校名称”，例如“加州大学尔湾分校”。\n",
    "    加州大学欧文分校请使用“加州大学尔湾分校”。\n",
    "    布兰戴斯大学请使用“布兰迪斯大学”。\n",
    "    威廉与玛丽学院和威廉与玛丽大学请使用“威廉玛丽学院”。\n",
    "    利哈伊大学请使用“里海大学”。\n",
    "    密歇根大学安娜堡分校需使用全称，不可缩写为“密歇根大学”。\n",
    "    伊利诺伊大学香槟分校需使用全称，不可缩写为“伊利诺伊大学”。\n",
    "    乔治亚大学请使用“佐治亚大学”。\n",
    "    华盛顿大学圣路易斯分校请使用“圣路易斯华盛顿大学”。\n",
    "5. 仅输出正文： 文章输出只包含正文部分，不包含标题。\n",
    "6. 图片占位符： 在文章中适当位置（尽量位于文章的上部且在两个段落之间）放置一个图片占位符，使用‘[image_placeholder]’表示。\n",
    "7. 参考文献： 在文章末尾添加参考文献。参考文献需包含原始文章中的引用内容，并且仅限实际在文中引用过的文献。对于重复的参考文献，请合并处理，确保每个引用都是独特且被引用的。\\\n",
    "参考文献格式应为链接，链接名使用“title”字段，链接地址使用“url”字段。\"\"\"\n",
    "    while len(content_array) == 0 or (len(content_array) - len(content_set)) > 0:\n",
    "        if repeat_N >= 4:\n",
    "            local_folder = get_local_folder()\n",
    "            file = os.path.join(get_local_folder(), \"repeat.txt\")\n",
    "            f = open(file, \"a\")\n",
    "            f.write(\n",
    "                state[\"url\"]\n",
    "                + \"\\n\\n---------------------------------------------------------------------\\n\\n\"\n",
    "            )\n",
    "            f.close()\n",
    "            raise Exception(\"rewrite CN version 4 times still get duplicates\")\n",
    "            break\n",
    "        rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_message),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"原始总结内容及支持扩展讨论话题的讨论：{documents}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        rewrite_chain = rewrite_prompt | llm_large | StrOutputParser()\n",
    "        content = rewrite_chain.invoke({\"documents\": documents})\n",
    "        content_array = content.split(\"\\n\\n\")\n",
    "        for element in content_array:\n",
    "            if len(element) <= 20:\n",
    "                content_array.remove(element)\n",
    "        content_set = set(content_array)\n",
    "        repeat_N = repeat_N + 1\n",
    "        system_message = (\n",
    "            system_message\n",
    "            + \"\\n\\n新的文章不要有重复的段落，如果遇到原始总结内容和扩展讨论点有重复内容的可以忽略重复内容，在最后的输出文章中不可以有重复段落。\"\n",
    "        )\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d0eb04-bdb6-4d2f-8529-85798f30a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_en(state):\n",
    "    summary = state[\"summary\"]\n",
    "    documents = state[\"documents\"]\n",
    "    topics = state[\"topics\"]\n",
    "    content_array = []\n",
    "    content_set = {}\n",
    "    repeat_N = 0\n",
    "    system_message = \"\"\"Role: You are an experienced commentator specializing in U.S. university news.\n",
    "Task: Below, you’ll find an original summary along with discussion topics and supporting arguments. Your goal is to craft a commentary article between 2,000 and 5,000 words.\\\n",
    "The article should expand on the original summary while emphasizing content related to U.S. colleges. Your final piece should reflect the following guidelines:\n",
    "1.\tContent Focus:\n",
    "    Begin with the original summary, then broaden the discussion while consistently tying back to it.\n",
    "    Integrate the provided discussion points and supporting arguments into the article seamlessly.\n",
    "    Maintain a clear and logical flow throughout the commentary, ensuring the entire article is coherent.\n",
    "2.\tCollege Mentions:\n",
    "    When introducing U.S. colleges for the first time, use their full English names (e.g., University of California-Berkeley).\n",
    "    Subsequent references can use appropriate abbreviations.\n",
    "3.\tArticle Structure:\n",
    "    Use headings starting from H2; there should be no H1 headings in your output.\n",
    "    Include an image placeholder represented as '[image_placeholder]' placed thoughtfully towards the upper-middle section of the article, ideally between two paragraphs.\n",
    "4.\tReferences:\n",
    "    Conclude with a comprehensive summary that ties together the original and expanded discussions.\n",
    "    Include only references that have been cited within the text, merging duplicates and removing any unnecessary entries.\n",
    "    The reference format should be hyperlinks with the following structure:\n",
    "    hyper link name: \"title\" of the reference\n",
    "    hpyer link url: \"url\" to the reference\n",
    "5.\tLanguage: The final article must be in English.\n",
    "\"\"\"\n",
    "    while len(content_array) == 0 or (len(content_array) - len(content_set)) > 0:\n",
    "        rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_message),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"Original summary and supporting arguments：\\n\\n{documents}\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        rewrite_chain = rewrite_prompt | llm_large | StrOutputParser()\n",
    "        content = rewrite_chain.invoke(\n",
    "            {\"summary\": summary, \"topics\": topics, \"documents\": documents}\n",
    "        )\n",
    "        content_array = content.split(\"\\n\\n\")\n",
    "        for element in content_array:\n",
    "            if len(element) <= 20:\n",
    "                content_array.remove(element)\n",
    "        content_set = set(content_array)\n",
    "        repeat_N = repeat_N + 1\n",
    "        if repeat_N >= 4:\n",
    "            local_folder = get_local_folder()\n",
    "            file = os.path.join(get_local_folder(), \"repeat.txt\")\n",
    "            f = open(file, \"a\")\n",
    "            f.write(\n",
    "                state[\"url\"]\n",
    "                + \"\\n\\n---------------------------------------------------------------------\\n\\n\"\n",
    "            )\n",
    "            f.close()\n",
    "            raise Exception(\"rewrite EN version 4 times still get duplicates\")\n",
    "            break\n",
    "        system_message = (\n",
    "            system_message\n",
    "            + \"\\n\\n新的文章不要有重复的段落，如果遇到原始总结内容和扩展讨论点有重复内容的可以忽略重复内容，在最后的输出文章中不可以有重复段落。\"\n",
    "        )\n",
    "    return {\"content_en\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89016558-85c0-450f-8d23-7613f7097793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_format(BaseModel):\n",
    "    title: str = Field(\n",
    "        description=\"与文章内容相关的文章中文标题，长度在20到30个中文字，用中文输出\"\n",
    "    )\n",
    "    title_en: str = Field(\n",
    "        description=\"与文章内容相关的文章英文标题，长度在10到20个英文单词，用英文输出\"\n",
    "    )\n",
    "    image_query: str = Field(\n",
    "        description=\"detailed prompt to generate an image that based on the article content, should be in English\"\n",
    "    )\n",
    "    image_filename: str = Field(\n",
    "        description=\"a good name for the image file without file extension, should be in English\"\n",
    "    )\n",
    "    tags: List[str] = Field(description=\"与文章内容相关的中文标签，用中文输出\")\n",
    "    tags_en: List[str] = Field(description=\"与文章内容相关的英文标签，用英文输出\")\n",
    "\n",
    "\n",
    "def article_metas(state):\n",
    "    content = state[\"content\"]\n",
    "    meta_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"请完成以下任务：\n",
    "                1. 根据下面给出的文章内容，为文章取一个合适的标题。标题需要有中文和英文两个版本，中文版标题长度在20到30个中文字，英文标题长度在10到20个英文单词。\n",
    "                2. 根据文章内容，生成一个详细的图像生成提示（image generation prompt），提示词应为英文，并注意使用不会违反“安全系统”的安全词汇。图像风格应基于文章内容。\n",
    "                3. 为上述图像生成提示生成一个英文的图像文件名，但不包含文件类型扩展名。\n",
    "                4. 生成一些与文章内容相关的标签，标签同样需要有中文和英文两个版本。\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"下面是需要处理的文章内容：\\n\\n{content}\"),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm_large.with_structured_output(meta_format, method=\"json_schema\")\n",
    "    meta_chain = meta_prompt | structured_llm\n",
    "    chain_n = 0\n",
    "    while True:\n",
    "        if chain_n > 3:\n",
    "            raise Exception(\"get article metas error with 3 trials\")\n",
    "        try:\n",
    "            response = meta_chain.invoke({\"content\": content})\n",
    "            break\n",
    "        except:\n",
    "            chain_n += 1\n",
    "\n",
    "    tag_names = response.tags\n",
    "    tags = tags_to_IDs(tag_names)\n",
    "    tag_names_en = response.tags_en\n",
    "    tags_en = tags_to_IDs_en(tag_names_en)\n",
    "    return {\n",
    "        \"title\": response.title,\n",
    "        \"title_en\": response.title_en,\n",
    "        \"image_query\": response.image_query,\n",
    "        \"image_filename\": response.image_filename,\n",
    "        \"tags\": tags,\n",
    "        \"tags_en\": tags_en,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3babcedf-31fa-4bfa-9003-69627a21c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(state):\n",
    "    image_filename = state[\"image_filename\"]\n",
    "    image_folder = os.path.join(get_local_folder(), \"images\")\n",
    "    png_image = os.path.join(image_folder, image_filename + \".png\")\n",
    "    jpg_image = os.path.join(image_folder, image_filename + \".jpg\")\n",
    "    image_query = state[\"image_query\"]\n",
    "    try:\n",
    "        image_url = DallEAPIWrapper(\n",
    "            model=\"dall-e-3\", size=\"1792x1024\", quality=\"standard\"\n",
    "        ).run(image_query)\n",
    "        urllib.request.urlretrieve(image_url, png_image)\n",
    "        with Image.open(png_image) as image:\n",
    "            image.save(jpg_image, optimized=True, quality=20)\n",
    "        os.remove(png_image)\n",
    "        response = post_wordpress_file(jpg_image, lang_type=\"cn\")\n",
    "        response = response.json()\n",
    "        image_ID = int(response.get(\"id\"))\n",
    "        image_url = response.get(\"guid\").get(\"rendered\")\n",
    "        response_en = post_wordpress_file(jpg_image, lang_type=\"en\")\n",
    "        response_en = response_en.json()\n",
    "        image_ID_en = int(response_en.get(\"id\"))\n",
    "        image_url_en = response_en.get(\"guid\").get(\"rendered\")\n",
    "        return {\n",
    "            \"image_ID\": image_ID,\n",
    "            \"image_url\": image_url,\n",
    "            \"image_ID_en\": image_ID_en,\n",
    "            \"image_url_en\": image_url_en,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\"image_ID\": -1, \"image_url\": \"\", \"image_ID_en\": -1, \"image_url_en\": \"\"}\n",
    "\n",
    "\n",
    "def publish_post(state):\n",
    "    title = state[\"title\"]\n",
    "    image_ID = state[\"image_ID\"]\n",
    "    image_url = state[\"image_url\"]\n",
    "    tags = state[\"tags\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.com/wp-content/uploads/2024/06/fp_college_news_default.jpg\"\n",
    "        image_ID = 107009\n",
    "    content = state[\"content\"]\n",
    "    raw_content = content\n",
    "    if content.find(\"[image_placeholder]\") > 0:\n",
    "        content = content.replace(\n",
    "            \"[image_placeholder]\", \"\"\"<img src=\"{}\">\"\"\".format(image_url)\n",
    "        )\n",
    "    else:\n",
    "        content = \"\"\"<img src=\"{}\">\"\"\".format(image_url) + content\n",
    "    content = markdown2.markdown(\n",
    "        content,\n",
    "        extras=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content)\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[3627],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"cn\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    post_ID = response.get(\"id\")\n",
    "    update_summary_qa(post_ID, raw_content, llm_small)\n",
    "    return\n",
    "\n",
    "\n",
    "def publish_post_en(state):\n",
    "    title = state[\"title_en\"]\n",
    "    image_ID = state[\"image_ID_en\"]\n",
    "    image_url = state[\"image_url_en\"]\n",
    "    tags = state[\"tags_en\"]\n",
    "    if image_ID == -1:\n",
    "        image_url = \"https://www.forwardpathway.us/wp-content/uploads/2024/07/fp_college_news_default.jpg\"\n",
    "        image_ID = 15899\n",
    "    content = state[\"content_en\"]\n",
    "    if content.find(\"[image_placeholder]\") > 0:\n",
    "        content = content.replace(\n",
    "            \"[image_placeholder]\", \"\"\"<img src=\"{}\">\"\"\".format(image_url)\n",
    "        )\n",
    "    else:\n",
    "        content = \"\"\"<img src=\"{}\">\"\"\".format(image_url) + content\n",
    "    content = markdown2.markdown(\n",
    "        content,\n",
    "        extras=[\"tables\", \"footnotes\"],\n",
    "    )\n",
    "    (content, new_tags) = insert_keyword_url(content, lang_type=\"en\")\n",
    "    tags = tags | new_tags\n",
    "    response = post_wordpress_post(\n",
    "        post_title=title,\n",
    "        post_body=content,\n",
    "        featured_media_id=image_ID,\n",
    "        tags=tags,\n",
    "        categories=[9],\n",
    "        comment_status=\"closed\",\n",
    "        lang_type=\"en\",\n",
    "    )\n",
    "    response = response.json()\n",
    "    post_ID = response.get(\"id\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d97d8c7-e31a-4d3f-9914-1b44d7b250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Build LangGraph ####################################\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"summary_node\", summary)\n",
    "workflow.add_node(\"more_topics\", more_topics)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"rewrite_en\", rewrite_en)\n",
    "workflow.add_node(\"article_metas\", article_metas)\n",
    "workflow.add_node(\"generate_image\", generate_image)\n",
    "workflow.add_node(\"publish_post\", publish_post)\n",
    "workflow.add_node(\"publish_post_en\", publish_post_en)\n",
    "\n",
    "workflow.set_entry_point(\"summary_node\")\n",
    "workflow.add_edge(\"summary_node\", \"more_topics\")\n",
    "workflow.add_conditional_edges(\"more_topics\", topics_to_search,[\"web_search\"])\n",
    "workflow.add_edge(\"web_search\", \"rewrite\")\n",
    "workflow.add_edge(\"web_search\", \"rewrite_en\")\n",
    "workflow.add_edge(\"rewrite\", \"article_metas\")\n",
    "workflow.add_edge(\"rewrite_en\", \"article_metas\")\n",
    "workflow.add_edge(\"article_metas\", \"generate_image\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post\")\n",
    "workflow.add_edge(\"generate_image\", \"publish_post_en\")\n",
    "workflow.add_edge(\"publish_post\", END)\n",
    "workflow.add_edge(\"publish_post_en\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3bfb9-ea4c-46ee-ae67-d80337ddaf97",
   "metadata": {},
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    IPImage(\n",
    "        app.get_graph(xray=1).draw_mermaid_png(\n",
    "            curve_style=CurveStyle.BASIS,\n",
    "            node_colors=NodeStyles(\n",
    "                first=\"fill:#FDFFB6\",\n",
    "                last=\"fill:#FFADAD\",\n",
    "                default=\"fill:#CAFFBF,line-height:1\",\n",
    "            ),\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        ),\n",
    "        width=300,\n",
    "    )\n",
    ")\n",
    "\n",
    "img = app.get_graph().draw_mermaid_png(\n",
    "    curve_style=CurveStyle.BASIS,\n",
    "    node_colors=NodeStyles(\n",
    "        first=\"fill:#FDFFB6\",\n",
    "        last=\"fill:#FFADAD\",\n",
    "        default=\"fill:#CAFFBF,line-height:1\",\n",
    "    ),\n",
    "    draw_method=MermaidDrawMethod.API,\n",
    ")\n",
    "with open(\"post_publish_flow_2.png\", \"wb\") as png:\n",
    "    png.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1dd4fed-1964-4fee-9bb7-9bc7a60d32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for url:  https://www.usnews.com/education/blogs/college-rankings-blog/articles/2024-08-27/2025-best-colleges-rankings-coming-sept-24\n",
      "Orginal url None error\n"
     ]
    }
   ],
   "source": [
    "#urls=[\"https://www.usnews.com/education/blogs/college-rankings-blog/articles/2024-08-27/2025-best-colleges-rankings-coming-sept-24\"]\n",
    "urls = get_news_urls()\n",
    "for url in urls:\n",
    "    try:\n",
    "        app.invoke({\"url\": url})\n",
    "        set_news_url_flag(url)\n",
    "        print(url, \"finished\")\n",
    "    except Exception as e:\n",
    "        print(\"error for url: \", url)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f441d-170a-4c57-81c4-8a341e95aa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
